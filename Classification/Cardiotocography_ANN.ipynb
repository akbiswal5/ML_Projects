{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "stYTutxxrWZb"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade xlrd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "EQDY6PFwjoJv",
        "outputId": "6ff67b7c-8e61-4ee0-8f81-7601d4c51d74"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Collecting xlrd\n",
            "  Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 3.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: xlrd\n",
            "  Attempting uninstall: xlrd\n",
            "    Found existing installation: xlrd 1.1.0\n",
            "    Uninstalling xlrd-1.1.0:\n",
            "      Successfully uninstalled xlrd-1.1.0\n",
            "Successfully installed xlrd-2.0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "xlrd"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBKP6NBhrexW"
      },
      "source": [
        "df=pd.read_excel('/content/CTG.xls',header=0,skipfooter=3,sheet_name=2)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "XYMISPP3re6T",
        "outputId": "b147d754-910d-45db-f5fc-0e4fae5aee2e"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       FileName       Date      SegFile      b       e    LBE     LB   AC  \\\n",
              "0           NaN        NaT          NaN    NaN     NaN    NaN    NaN  NaN   \n",
              "1  Variab10.txt 1996-12-01  CTG0001.txt  240.0   357.0  120.0  120.0  0.0   \n",
              "2    Fmcs_1.txt 1996-05-03  CTG0002.txt    5.0   632.0  132.0  132.0  4.0   \n",
              "3    Fmcs_1.txt 1996-05-03  CTG0003.txt  177.0   779.0  133.0  133.0  2.0   \n",
              "4    Fmcs_1.txt 1996-05-03  CTG0004.txt  411.0  1192.0  134.0  134.0  2.0   \n",
              "\n",
              "    FM   UC  ...    C    D    E   AD   DE   LD   FS  SUSP  CLASS  NSP  \n",
              "0  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   NaN    NaN  NaN  \n",
              "1  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   0.0    9.0  2.0  \n",
              "2  0.0  4.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
              "3  0.0  5.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
              "4  0.0  6.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
              "\n",
              "[5 rows x 40 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-818c10f6-4cc9-4a3b-a375-dc395f76bb51\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FileName</th>\n",
              "      <th>Date</th>\n",
              "      <th>SegFile</th>\n",
              "      <th>b</th>\n",
              "      <th>e</th>\n",
              "      <th>LBE</th>\n",
              "      <th>LB</th>\n",
              "      <th>AC</th>\n",
              "      <th>FM</th>\n",
              "      <th>UC</th>\n",
              "      <th>...</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>AD</th>\n",
              "      <th>DE</th>\n",
              "      <th>LD</th>\n",
              "      <th>FS</th>\n",
              "      <th>SUSP</th>\n",
              "      <th>CLASS</th>\n",
              "      <th>NSP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Variab10.txt</td>\n",
              "      <td>1996-12-01</td>\n",
              "      <td>CTG0001.txt</td>\n",
              "      <td>240.0</td>\n",
              "      <td>357.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Fmcs_1.txt</td>\n",
              "      <td>1996-05-03</td>\n",
              "      <td>CTG0002.txt</td>\n",
              "      <td>5.0</td>\n",
              "      <td>632.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Fmcs_1.txt</td>\n",
              "      <td>1996-05-03</td>\n",
              "      <td>CTG0003.txt</td>\n",
              "      <td>177.0</td>\n",
              "      <td>779.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Fmcs_1.txt</td>\n",
              "      <td>1996-05-03</td>\n",
              "      <td>CTG0004.txt</td>\n",
              "      <td>411.0</td>\n",
              "      <td>1192.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 40 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-818c10f6-4cc9-4a3b-a375-dc395f76bb51')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-818c10f6-4cc9-4a3b-a375-dc395f76bb51 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-818c10f6-4cc9-4a3b-a375-dc395f76bb51');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4Y2GGlbrfBK"
      },
      "source": [
        "df=df.dropna(axis=0, how='all')\n",
        "df=df.dropna(axis=1, how='all')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ropmN0w2mbSJ",
        "outputId": "6e5c02b9-d093-45b2-d170-429c9865b896"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2126, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DlzkGpnmYYZ",
        "outputId": "f7db0d8c-3664-446f-899a-f8b6895cdea1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['FileName', 'Date', 'SegFile', 'b', 'e', 'LBE', 'LB', 'AC', 'FM', 'UC',\n",
              "       'ASTV', 'MSTV', 'ALTV', 'MLTV', 'DL', 'DS', 'DP', 'DR', 'Width', 'Min',\n",
              "       'Max', 'Nmax', 'Nzeros', 'Mode', 'Mean', 'Median', 'Variance',\n",
              "       'Tendency', 'A', 'B', 'C', 'D', 'E', 'AD', 'DE', 'LD', 'FS', 'SUSP',\n",
              "       'CLASS', 'NSP'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRjpGkBgmYhm",
        "outputId": "ff02bc5d-a680-4016-eec9-4455c9b8d32b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzQkzhFNrfHn"
      },
      "source": [
        "#drop irrelevant columns\n",
        "df.drop(columns=['FileName', 'Date', 'SegFile','b','e','LBE', 'A', 'B', 'C', 'D', 'E', 'AD', 'DE', 'LD', 'FS', 'SUSP', 'DR','CLASS'], inplace=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az_77k_grfKv",
        "outputId": "7554fc79-1bad-41ba-bd8a-5e920211f55c"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2126, 22)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "Kpx7XVf2y3LN",
        "outputId": "030f9b5d-16e2-4b3d-d004-47e8cabf956a"
      },
      "source": [
        "df.describe().transpose()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           count        mean        std    min    25%    50%    75%    max\n",
              "LB        2126.0  133.303857   9.840844  106.0  126.0  133.0  140.0  160.0\n",
              "AC        2126.0    2.722484   3.560850    0.0    0.0    1.0    4.0   26.0\n",
              "FM        2126.0    7.241298  37.125309    0.0    0.0    0.0    2.0  564.0\n",
              "UC        2126.0    3.659925   2.847094    0.0    1.0    3.0    5.0   23.0\n",
              "ASTV      2126.0   46.990122  17.192814   12.0   32.0   49.0   61.0   87.0\n",
              "MSTV      2126.0    1.332785   0.883241    0.2    0.7    1.2    1.7    7.0\n",
              "ALTV      2126.0    9.846660  18.396880    0.0    0.0    0.0   11.0   91.0\n",
              "MLTV      2126.0    8.187629   5.628247    0.0    4.6    7.4   10.8   50.7\n",
              "DL        2126.0    1.570085   2.499229    0.0    0.0    0.0    3.0   16.0\n",
              "DS        2126.0    0.003293   0.057300    0.0    0.0    0.0    0.0    1.0\n",
              "DP        2126.0    0.126058   0.464361    0.0    0.0    0.0    0.0    4.0\n",
              "Width     2126.0   70.445908  38.955693    3.0   37.0   67.5  100.0  180.0\n",
              "Min       2126.0   93.579492  29.560212   50.0   67.0   93.0  120.0  159.0\n",
              "Max       2126.0  164.025400  17.944183  122.0  152.0  162.0  174.0  238.0\n",
              "Nmax      2126.0    4.068203   2.949386    0.0    2.0    3.0    6.0   18.0\n",
              "Nzeros    2126.0    0.323612   0.706059    0.0    0.0    0.0    0.0   10.0\n",
              "Mode      2126.0  137.452023  16.381289   60.0  129.0  139.0  148.0  187.0\n",
              "Mean      2126.0  134.610536  15.593596   73.0  125.0  136.0  145.0  182.0\n",
              "Median    2126.0  138.090310  14.466589   77.0  129.0  139.0  148.0  186.0\n",
              "Variance  2126.0   18.808090  28.977636    0.0    2.0    7.0   24.0  269.0\n",
              "Tendency  2126.0    0.320320   0.610829   -1.0    0.0    0.0    1.0    1.0\n",
              "NSP       2126.0    1.304327   0.614377    1.0    1.0    1.0    1.0    3.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb90cb06-db0c-4b04-b703-64ccfda43df1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LB</th>\n",
              "      <td>2126.0</td>\n",
              "      <td>133.303857</td>\n",
              "      <td>9.840844</td>\n",
              "      <td>106.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>160.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AC</th>\n",
              "      <td>2126.0</td>\n",
              "      <td>2.722484</td>\n",
              "      <td>3.560850</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FM</th>\n",
              "      <td>2126.0</td>\n",
              "      <td>7.241298</td>\n",
              "      <td>37.125309</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>564.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>UC</th>\n",
              "      <td>2126.0</td>\n",
              "      <td>3.659925</td>\n",
              "      <td>2.847094</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ASTV</th>\n",
              "      <td>2126.0</td>\n",
              "      <td>46.990122</td>\n",
              "      <td>17.192814</td>\n",
              "      <td>12.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>87.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSTV</th>\n",
              "      <td>2126.0</td>\n",
              "      <td>1.332785</td>\n",
              "      <td>0.883241</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.7</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.7</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ALTV</th>\n",
              "      <td>2126.0</td>\n",
              "      <td>9.846660</td>\n",
              "      <td>18.396880</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>91.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLTV</th>\n",
              "      <td>2126.0</td>\n",
              "      <td>8.187629</td>\n",
              "      <td>5.628247</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.6</td>\n",
              "      <td>7.4</td>\n",
              "      <td>10.8</td>\n",
              "      <td>50.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DL</th>\n",
              "      <td>2126.0</td>\n",
              "      <td>1.570085</td>\n",
              "      <td>2.499229</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DS</th>\n",
              "      <td>2126.0</td>\n",
              "      <td>0.003293</td>\n",
              "      <td>0.057300</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DP</th>\n",
              "      <td>2126.0</td>\n",
              "      <td>0.126058</td>\n",
              "      <td>0.464361</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Width</th>\n",
              "      <td>2126.0</td>\n",
              "      <td>70.445908</td>\n",
              "      <td>38.955693</td>\n",
              "      <td>3.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>67.5</td>\n",
              "      <td>100.0</td>\n",
              "      <td>180.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Min</th>\n",
              "      <td>2126.0</td>\n",
              "      <td>93.579492</td>\n",
              "      <td>29.560212</td>\n",
              "      <td>50.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>159.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max</th>\n",
              "      <td>2126.0</td>\n",
              "      <td>164.025400</td>\n",
              "      <td>17.944183</td>\n",
              "      <td>122.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>238.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nmax</th>\n",
              "      <td>2126.0</td>\n",
              "      <td>4.068203</td>\n",
              "      <td>2.949386</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nzeros</th>\n",
              "      <td>2126.0</td>\n",
              "      <td>0.323612</td>\n",
              "      <td>0.706059</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mode</th>\n",
              "      <td>2126.0</td>\n",
              "      <td>137.452023</td>\n",
              "      <td>16.381289</td>\n",
              "      <td>60.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>187.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>2126.0</td>\n",
              "      <td>134.610536</td>\n",
              "      <td>15.593596</td>\n",
              "      <td>73.0</td>\n",
              "      <td>125.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>182.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Median</th>\n",
              "      <td>2126.0</td>\n",
              "      <td>138.090310</td>\n",
              "      <td>14.466589</td>\n",
              "      <td>77.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>186.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variance</th>\n",
              "      <td>2126.0</td>\n",
              "      <td>18.808090</td>\n",
              "      <td>28.977636</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>269.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tendency</th>\n",
              "      <td>2126.0</td>\n",
              "      <td>0.320320</td>\n",
              "      <td>0.610829</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NSP</th>\n",
              "      <td>2126.0</td>\n",
              "      <td>1.304327</td>\n",
              "      <td>0.614377</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb90cb06-db0c-4b04-b703-64ccfda43df1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb90cb06-db0c-4b04-b703-64ccfda43df1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb90cb06-db0c-4b04-b703-64ccfda43df1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert to binary classification- normal & suspecious/pathalogi\n",
        "df['NSP']=df['NSP'].apply(lambda x:0 if x==1 else 1)"
      ],
      "metadata": {
        "id": "37z33p4woSVJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['NSP'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNa0SwT4oSY9",
        "outputId": "7852416a-5aa9-4fff-e41a-8dc7d4b015d8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1655\n",
              "1     471\n",
              "Name: NSP, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Divide the data\n",
        "X=df.iloc[:,:21]\n",
        "y=df.iloc[:,21]"
      ],
      "metadata": {
        "id": "aYrVDl30oSc6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "sUqudxsAoSgP",
        "outputId": "2aa043f1-43a2-471c-e317-d408126ec2e4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      LB   AC   FM   UC  ASTV  MSTV  ALTV  MLTV   DL   DS  ...  Width   Min  \\\n",
              "1  120.0  0.0  0.0  0.0  73.0   0.5  43.0   2.4  0.0  0.0  ...   64.0  62.0   \n",
              "2  132.0  4.0  0.0  4.0  17.0   2.1   0.0  10.4  2.0  0.0  ...  130.0  68.0   \n",
              "3  133.0  2.0  0.0  5.0  16.0   2.1   0.0  13.4  2.0  0.0  ...  130.0  68.0   \n",
              "4  134.0  2.0  0.0  6.0  16.0   2.4   0.0  23.0  2.0  0.0  ...  117.0  53.0   \n",
              "5  132.0  4.0  0.0  5.0  16.0   2.4   0.0  19.9  0.0  0.0  ...  117.0  53.0   \n",
              "\n",
              "     Max  Nmax  Nzeros   Mode   Mean  Median  Variance  Tendency  \n",
              "1  126.0   2.0     0.0  120.0  137.0   121.0      73.0       1.0  \n",
              "2  198.0   6.0     1.0  141.0  136.0   140.0      12.0       0.0  \n",
              "3  198.0   5.0     1.0  141.0  135.0   138.0      13.0       0.0  \n",
              "4  170.0  11.0     0.0  137.0  134.0   137.0      13.0       1.0  \n",
              "5  170.0   9.0     0.0  137.0  136.0   138.0      11.0       1.0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b47a6f07-f456-4bf1-a632-970c3f307e49\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LB</th>\n",
              "      <th>AC</th>\n",
              "      <th>FM</th>\n",
              "      <th>UC</th>\n",
              "      <th>ASTV</th>\n",
              "      <th>MSTV</th>\n",
              "      <th>ALTV</th>\n",
              "      <th>MLTV</th>\n",
              "      <th>DL</th>\n",
              "      <th>DS</th>\n",
              "      <th>...</th>\n",
              "      <th>Width</th>\n",
              "      <th>Min</th>\n",
              "      <th>Max</th>\n",
              "      <th>Nmax</th>\n",
              "      <th>Nzeros</th>\n",
              "      <th>Mode</th>\n",
              "      <th>Mean</th>\n",
              "      <th>Median</th>\n",
              "      <th>Variance</th>\n",
              "      <th>Tendency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>43.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>64.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>132.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>130.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>133.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>130.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>134.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>117.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>132.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>117.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b47a6f07-f456-4bf1-a632-970c3f307e49')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b47a6f07-f456-4bf1-a632-970c3f307e49 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b47a6f07-f456-4bf1-a632-970c3f307e49');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB8S_KnVoSiO",
        "outputId": "4ec267d8-c003-4942-c581-85feeb2f6b2e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1       1\n",
              "2       0\n",
              "3       0\n",
              "4       0\n",
              "5       0\n",
              "       ..\n",
              "2122    1\n",
              "2123    1\n",
              "2124    1\n",
              "2125    1\n",
              "2126    0\n",
              "Name: NSP, Length: 2126, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBkVlu-lzwPQ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOq-tOS3zwR6"
      },
      "source": [
        "#feature engineering\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eQC5txysUMH",
        "outputId": "7df3e5ab-bf96-4a47-eef3-c66bf643e272"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.03297075, -0.76037189, -0.07538122, ..., -0.43989944,\n",
              "        -0.33270075,  1.09954375],\n",
              "       [-0.64765343, -0.76037189, -0.1976169 , ..., -1.00175817,\n",
              "        -0.64380262, -0.54307362],\n",
              "       [-1.05744188,  3.4480753 , -0.13649906, ..., -0.01850538,\n",
              "        -0.29813387,  1.09954375],\n",
              "       ...,\n",
              "       [-0.4427592 ,  0.08131755, -0.16705798, ..., -0.08873773,\n",
              "        -0.4018345 , -0.54307362],\n",
              "       [-0.54520631,  0.08131755, -0.1976169 , ..., -0.15897007,\n",
              "         0.25493612,  1.09954375],\n",
              "       [-1.9794659 , -0.76037189, -0.1976169 , ..., -1.5636169 ,\n",
              "        -0.64380262, -0.54307362]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EkaAXJisYyv",
        "outputId": "b67ba732-576e-4d59-e5e8-ea9fb310df37"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.34031209, -0.47980874, -0.1976169 , ..., -0.22920241,\n",
              "        -0.60923574, -0.54307362],\n",
              "       [ 0.06947637,  1.76469642, -0.16705798, ...,  0.82428272,\n",
              "         0.49690424, -0.54307362],\n",
              "       [-0.85254765, -0.47980874, -0.1976169 , ..., -0.43989944,\n",
              "        -0.60923574, -0.54307362],\n",
              "       ...,\n",
              "       [-0.03297075, -0.1992456 , -0.1976169 , ...,  0.26242398,\n",
              "        -0.54010199,  1.09954375],\n",
              "       [-0.75010054,  0.08131755, -0.13649906, ..., -0.43989944,\n",
              "        -0.29813387,  1.09954375],\n",
              "       [-0.34031209,  0.92300699, 16.82370109, ..., -0.36966709,\n",
              "         0.289503  , -0.54307362]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnXDpHPUsdVA",
        "outputId": "6d928296-8a94-4bf5-bb3f-2ebc6a9fe22b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1594, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANN**"
      ],
      "metadata": {
        "id": "5JZZA_6ztDg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,ReLU,PReLU\n",
        "from tensorflow.keras.layers import Dropout"
      ],
      "metadata": {
        "id": "_eI0ZKittlw5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize ANN\n",
        "classifier=Sequential()"
      ],
      "metadata": {
        "id": "6pQinWpNvkuU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Input layer\n",
        "classifier.add(Dense(units=21,activation='relu'))"
      ],
      "metadata": {
        "id": "v8SjNk4evkz_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#First hidden layer\n",
        "classifier.add(Dense(units=15,activation='relu'))"
      ],
      "metadata": {
        "id": "cfCfTIGMvk5d"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#second hidden layer\n",
        "classifier.add(Dense(units=10,activation='relu'))"
      ],
      "metadata": {
        "id": "D_IHGjcsvk-v"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#output layer\n",
        "classifier.add(Dense(units=1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "0UmTg04hwzUw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "opt = tensorflow.keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "metadata": {
        "id": "vXVZAndAxiKx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compile ANN\n",
        "classifier.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "CIZEugX-wzZe"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_history = classifier.fit(X_train, y_train, validation_split=0.33,batch_size=16, epochs=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeIHrxTOwzdY",
        "outputId": "87dabf6e-0370-47b5-b4f5-10ccbf269908"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "67/67 [==============================] - 1s 6ms/step - loss: 0.5672 - accuracy: 0.7835 - val_loss: 0.5001 - val_accuracy: 0.7723\n",
            "Epoch 2/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7901 - val_loss: 0.3834 - val_accuracy: 0.8235\n",
            "Epoch 3/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.3316 - accuracy: 0.8519 - val_loss: 0.2904 - val_accuracy: 0.8710\n",
            "Epoch 4/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.2614 - accuracy: 0.8922 - val_loss: 0.2308 - val_accuracy: 0.8918\n",
            "Epoch 5/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.2185 - accuracy: 0.9157 - val_loss: 0.2021 - val_accuracy: 0.9089\n",
            "Epoch 6/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.1962 - accuracy: 0.9175 - val_loss: 0.1931 - val_accuracy: 0.9203\n",
            "Epoch 7/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.1851 - accuracy: 0.9185 - val_loss: 0.1797 - val_accuracy: 0.9241\n",
            "Epoch 8/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.1747 - accuracy: 0.9203 - val_loss: 0.1771 - val_accuracy: 0.9241\n",
            "Epoch 9/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.1694 - accuracy: 0.9260 - val_loss: 0.1809 - val_accuracy: 0.9203\n",
            "Epoch 10/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.1631 - accuracy: 0.9288 - val_loss: 0.1707 - val_accuracy: 0.9222\n",
            "Epoch 11/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.1579 - accuracy: 0.9260 - val_loss: 0.1664 - val_accuracy: 0.9241\n",
            "Epoch 12/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.1536 - accuracy: 0.9335 - val_loss: 0.1671 - val_accuracy: 0.9222\n",
            "Epoch 13/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.1493 - accuracy: 0.9306 - val_loss: 0.1675 - val_accuracy: 0.9260\n",
            "Epoch 14/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9372 - val_loss: 0.1685 - val_accuracy: 0.9222\n",
            "Epoch 15/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.1416 - accuracy: 0.9410 - val_loss: 0.1728 - val_accuracy: 0.9241\n",
            "Epoch 16/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.1350 - accuracy: 0.9381 - val_loss: 0.1673 - val_accuracy: 0.9203\n",
            "Epoch 17/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.1330 - accuracy: 0.9438 - val_loss: 0.1651 - val_accuracy: 0.9298\n",
            "Epoch 18/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.1306 - accuracy: 0.9475 - val_loss: 0.1788 - val_accuracy: 0.9184\n",
            "Epoch 19/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.1254 - accuracy: 0.9428 - val_loss: 0.1754 - val_accuracy: 0.9184\n",
            "Epoch 20/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.1226 - accuracy: 0.9475 - val_loss: 0.1741 - val_accuracy: 0.9165\n",
            "Epoch 21/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.1194 - accuracy: 0.9485 - val_loss: 0.1717 - val_accuracy: 0.9222\n",
            "Epoch 22/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.1152 - accuracy: 0.9531 - val_loss: 0.1739 - val_accuracy: 0.9184\n",
            "Epoch 23/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.1125 - accuracy: 0.9485 - val_loss: 0.1777 - val_accuracy: 0.9165\n",
            "Epoch 24/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.1090 - accuracy: 0.9531 - val_loss: 0.1828 - val_accuracy: 0.9184\n",
            "Epoch 25/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.1074 - accuracy: 0.9522 - val_loss: 0.1768 - val_accuracy: 0.9089\n",
            "Epoch 26/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.1046 - accuracy: 0.9578 - val_loss: 0.1765 - val_accuracy: 0.9165\n",
            "Epoch 27/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.1012 - accuracy: 0.9616 - val_loss: 0.1816 - val_accuracy: 0.9203\n",
            "Epoch 28/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0996 - accuracy: 0.9578 - val_loss: 0.1810 - val_accuracy: 0.9165\n",
            "Epoch 29/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0986 - accuracy: 0.9644 - val_loss: 0.1785 - val_accuracy: 0.9146\n",
            "Epoch 30/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0938 - accuracy: 0.9625 - val_loss: 0.1818 - val_accuracy: 0.9127\n",
            "Epoch 31/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0934 - accuracy: 0.9616 - val_loss: 0.1855 - val_accuracy: 0.9184\n",
            "Epoch 32/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0898 - accuracy: 0.9616 - val_loss: 0.1842 - val_accuracy: 0.9089\n",
            "Epoch 33/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0874 - accuracy: 0.9672 - val_loss: 0.1935 - val_accuracy: 0.9127\n",
            "Epoch 34/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0866 - accuracy: 0.9653 - val_loss: 0.2008 - val_accuracy: 0.9051\n",
            "Epoch 35/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0855 - accuracy: 0.9653 - val_loss: 0.1922 - val_accuracy: 0.9127\n",
            "Epoch 36/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0831 - accuracy: 0.9672 - val_loss: 0.1982 - val_accuracy: 0.9127\n",
            "Epoch 37/1000\n",
            "67/67 [==============================] - 0s 2ms/step - loss: 0.0791 - accuracy: 0.9709 - val_loss: 0.1931 - val_accuracy: 0.9127\n",
            "Epoch 38/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0819 - accuracy: 0.9691 - val_loss: 0.1982 - val_accuracy: 0.9165\n",
            "Epoch 39/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0759 - accuracy: 0.9719 - val_loss: 0.2055 - val_accuracy: 0.9108\n",
            "Epoch 40/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.9728 - val_loss: 0.2052 - val_accuracy: 0.9146\n",
            "Epoch 41/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.9728 - val_loss: 0.2123 - val_accuracy: 0.9032\n",
            "Epoch 42/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.9700 - val_loss: 0.2095 - val_accuracy: 0.9127\n",
            "Epoch 43/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9728 - val_loss: 0.2202 - val_accuracy: 0.9089\n",
            "Epoch 44/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.9738 - val_loss: 0.2137 - val_accuracy: 0.9222\n",
            "Epoch 45/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.9756 - val_loss: 0.2113 - val_accuracy: 0.9165\n",
            "Epoch 46/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9747 - val_loss: 0.2209 - val_accuracy: 0.9108\n",
            "Epoch 47/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9756 - val_loss: 0.2248 - val_accuracy: 0.9108\n",
            "Epoch 48/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9719 - val_loss: 0.2184 - val_accuracy: 0.9222\n",
            "Epoch 49/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.9747 - val_loss: 0.2313 - val_accuracy: 0.9203\n",
            "Epoch 50/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9784 - val_loss: 0.2274 - val_accuracy: 0.9203\n",
            "Epoch 51/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9766 - val_loss: 0.2345 - val_accuracy: 0.9241\n",
            "Epoch 52/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9747 - val_loss: 0.2305 - val_accuracy: 0.9184\n",
            "Epoch 53/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9794 - val_loss: 0.2427 - val_accuracy: 0.9184\n",
            "Epoch 54/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9775 - val_loss: 0.2549 - val_accuracy: 0.9089\n",
            "Epoch 55/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9794 - val_loss: 0.2447 - val_accuracy: 0.9184\n",
            "Epoch 56/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9831 - val_loss: 0.2593 - val_accuracy: 0.9203\n",
            "Epoch 57/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.9747 - val_loss: 0.2425 - val_accuracy: 0.9165\n",
            "Epoch 58/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9831 - val_loss: 0.2547 - val_accuracy: 0.9127\n",
            "Epoch 59/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9850 - val_loss: 0.2513 - val_accuracy: 0.9184\n",
            "Epoch 60/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9869 - val_loss: 0.2687 - val_accuracy: 0.9184\n",
            "Epoch 61/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9794 - val_loss: 0.2731 - val_accuracy: 0.9241\n",
            "Epoch 62/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 0.9869 - val_loss: 0.2694 - val_accuracy: 0.9260\n",
            "Epoch 63/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0450 - accuracy: 0.9850 - val_loss: 0.2790 - val_accuracy: 0.9241\n",
            "Epoch 64/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9869 - val_loss: 0.2834 - val_accuracy: 0.9127\n",
            "Epoch 65/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9859 - val_loss: 0.2809 - val_accuracy: 0.9184\n",
            "Epoch 66/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9878 - val_loss: 0.2890 - val_accuracy: 0.9241\n",
            "Epoch 67/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9850 - val_loss: 0.2953 - val_accuracy: 0.9203\n",
            "Epoch 68/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9869 - val_loss: 0.3023 - val_accuracy: 0.9184\n",
            "Epoch 69/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9859 - val_loss: 0.3027 - val_accuracy: 0.9241\n",
            "Epoch 70/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0372 - accuracy: 0.9859 - val_loss: 0.3020 - val_accuracy: 0.9165\n",
            "Epoch 71/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 0.9869 - val_loss: 0.3166 - val_accuracy: 0.9184\n",
            "Epoch 72/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9878 - val_loss: 0.3089 - val_accuracy: 0.9184\n",
            "Epoch 73/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.0339 - accuracy: 0.9878 - val_loss: 0.3181 - val_accuracy: 0.9241\n",
            "Epoch 74/1000\n",
            "67/67 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 0.9850 - val_loss: 0.3318 - val_accuracy: 0.9184\n",
            "Epoch 75/1000\n",
            "67/67 [==============================] - 0s 6ms/step - loss: 0.0347 - accuracy: 0.9850 - val_loss: 0.3429 - val_accuracy: 0.9222\n",
            "Epoch 76/1000\n",
            "67/67 [==============================] - 0s 5ms/step - loss: 0.0312 - accuracy: 0.9869 - val_loss: 0.3280 - val_accuracy: 0.9203\n",
            "Epoch 77/1000\n",
            "67/67 [==============================] - 0s 5ms/step - loss: 0.0316 - accuracy: 0.9878 - val_loss: 0.3517 - val_accuracy: 0.9146\n",
            "Epoch 78/1000\n",
            "67/67 [==============================] - 0s 5ms/step - loss: 0.0299 - accuracy: 0.9869 - val_loss: 0.3420 - val_accuracy: 0.9108\n",
            "Epoch 79/1000\n",
            "67/67 [==============================] - 0s 6ms/step - loss: 0.0342 - accuracy: 0.9859 - val_loss: 0.3588 - val_accuracy: 0.9032\n",
            "Epoch 80/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.0394 - accuracy: 0.9850 - val_loss: 0.3423 - val_accuracy: 0.9184\n",
            "Epoch 81/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 0.9878 - val_loss: 0.3647 - val_accuracy: 0.9146\n",
            "Epoch 82/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 0.9831 - val_loss: 0.3427 - val_accuracy: 0.9146\n",
            "Epoch 83/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0284 - accuracy: 0.9878 - val_loss: 0.3490 - val_accuracy: 0.9146\n",
            "Epoch 84/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 0.9897 - val_loss: 0.3643 - val_accuracy: 0.9165\n",
            "Epoch 85/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0238 - accuracy: 0.9888 - val_loss: 0.3717 - val_accuracy: 0.9146\n",
            "Epoch 86/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 0.9906 - val_loss: 0.3828 - val_accuracy: 0.9146\n",
            "Epoch 87/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 0.9888 - val_loss: 0.3766 - val_accuracy: 0.9222\n",
            "Epoch 88/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 0.9906 - val_loss: 0.3999 - val_accuracy: 0.9184\n",
            "Epoch 89/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 0.9897 - val_loss: 0.3851 - val_accuracy: 0.9184\n",
            "Epoch 90/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 0.9888 - val_loss: 0.3835 - val_accuracy: 0.9184\n",
            "Epoch 91/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.9897 - val_loss: 0.3974 - val_accuracy: 0.9222\n",
            "Epoch 92/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.9934 - val_loss: 0.4064 - val_accuracy: 0.9222\n",
            "Epoch 93/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.4188 - val_accuracy: 0.9184\n",
            "Epoch 94/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 0.9888 - val_loss: 0.4010 - val_accuracy: 0.9203\n",
            "Epoch 95/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 0.9916 - val_loss: 0.4030 - val_accuracy: 0.9222\n",
            "Epoch 96/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 0.9934 - val_loss: 0.4189 - val_accuracy: 0.9165\n",
            "Epoch 97/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9916 - val_loss: 0.4280 - val_accuracy: 0.9222\n",
            "Epoch 98/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9906 - val_loss: 0.4166 - val_accuracy: 0.9260\n",
            "Epoch 99/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 0.4553 - val_accuracy: 0.9165\n",
            "Epoch 100/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9934 - val_loss: 0.5002 - val_accuracy: 0.9146\n",
            "Epoch 101/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.4549 - val_accuracy: 0.9146\n",
            "Epoch 102/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.9963 - val_loss: 0.4737 - val_accuracy: 0.9146\n",
            "Epoch 103/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.4725 - val_accuracy: 0.9184\n",
            "Epoch 104/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 0.4715 - val_accuracy: 0.9203\n",
            "Epoch 105/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0327 - accuracy: 0.9878 - val_loss: 0.5231 - val_accuracy: 0.9089\n",
            "Epoch 106/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9859 - val_loss: 0.4957 - val_accuracy: 0.9146\n",
            "Epoch 107/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9794 - val_loss: 0.5286 - val_accuracy: 0.9165\n",
            "Epoch 108/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.9953 - val_loss: 0.4780 - val_accuracy: 0.9184\n",
            "Epoch 109/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9934 - val_loss: 0.4629 - val_accuracy: 0.9127\n",
            "Epoch 110/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9934 - val_loss: 0.4605 - val_accuracy: 0.9184\n",
            "Epoch 111/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9972 - val_loss: 0.4822 - val_accuracy: 0.9146\n",
            "Epoch 112/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.4702 - val_accuracy: 0.9146\n",
            "Epoch 113/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9972 - val_loss: 0.4721 - val_accuracy: 0.9184\n",
            "Epoch 114/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.4723 - val_accuracy: 0.9165\n",
            "Epoch 115/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9981 - val_loss: 0.4816 - val_accuracy: 0.9146\n",
            "Epoch 116/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.4733 - val_accuracy: 0.9241\n",
            "Epoch 117/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.4785 - val_accuracy: 0.9165\n",
            "Epoch 118/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.4970 - val_accuracy: 0.9108\n",
            "Epoch 119/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.9981 - val_loss: 0.5014 - val_accuracy: 0.9089\n",
            "Epoch 120/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.5054 - val_accuracy: 0.9203\n",
            "Epoch 121/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.4916 - val_accuracy: 0.9146\n",
            "Epoch 122/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.4884 - val_accuracy: 0.9222\n",
            "Epoch 123/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9953 - val_loss: 0.4996 - val_accuracy: 0.9165\n",
            "Epoch 124/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9981 - val_loss: 0.5410 - val_accuracy: 0.9165\n",
            "Epoch 125/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.5375 - val_accuracy: 0.9146\n",
            "Epoch 126/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.5060 - val_accuracy: 0.9127\n",
            "Epoch 127/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9991 - val_loss: 0.5189 - val_accuracy: 0.9108\n",
            "Epoch 128/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.5299 - val_accuracy: 0.9146\n",
            "Epoch 129/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 0.5173 - val_accuracy: 0.9127\n",
            "Epoch 130/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.5390 - val_accuracy: 0.9146\n",
            "Epoch 131/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 0.5528 - val_accuracy: 0.9070\n",
            "Epoch 132/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.5355 - val_accuracy: 0.9127\n",
            "Epoch 133/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9991 - val_loss: 0.5267 - val_accuracy: 0.9184\n",
            "Epoch 134/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.5282 - val_accuracy: 0.9184\n",
            "Epoch 135/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.5655 - val_accuracy: 0.9146\n",
            "Epoch 136/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.5575 - val_accuracy: 0.9127\n",
            "Epoch 137/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 0.5601 - val_accuracy: 0.9108\n",
            "Epoch 138/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.5433 - val_accuracy: 0.9165\n",
            "Epoch 139/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5562 - val_accuracy: 0.9127\n",
            "Epoch 140/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.5561 - val_accuracy: 0.9146\n",
            "Epoch 141/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.5615 - val_accuracy: 0.9108\n",
            "Epoch 142/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9972 - val_loss: 0.6031 - val_accuracy: 0.9146\n",
            "Epoch 143/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9991 - val_loss: 0.5774 - val_accuracy: 0.9165\n",
            "Epoch 144/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.6053 - val_accuracy: 0.9127\n",
            "Epoch 145/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.5827 - val_accuracy: 0.9127\n",
            "Epoch 146/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5874 - val_accuracy: 0.9127\n",
            "Epoch 147/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.5969 - val_accuracy: 0.9127\n",
            "Epoch 148/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5895 - val_accuracy: 0.9127\n",
            "Epoch 149/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.5984 - val_accuracy: 0.9165\n",
            "Epoch 150/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.6189 - val_accuracy: 0.9184\n",
            "Epoch 151/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.6106 - val_accuracy: 0.9127\n",
            "Epoch 152/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6045 - val_accuracy: 0.9165\n",
            "Epoch 153/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.6155 - val_accuracy: 0.9127\n",
            "Epoch 154/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.6217 - val_accuracy: 0.9127\n",
            "Epoch 155/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6100 - val_accuracy: 0.9127\n",
            "Epoch 156/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6214 - val_accuracy: 0.9108\n",
            "Epoch 157/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6145 - val_accuracy: 0.9165\n",
            "Epoch 158/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6224 - val_accuracy: 0.9127\n",
            "Epoch 159/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6152 - val_accuracy: 0.9184\n",
            "Epoch 160/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6376 - val_accuracy: 0.9127\n",
            "Epoch 161/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6441 - val_accuracy: 0.9146\n",
            "Epoch 162/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6348 - val_accuracy: 0.9127\n",
            "Epoch 163/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.6298 - val_accuracy: 0.9203\n",
            "Epoch 164/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.6600 - val_accuracy: 0.9146\n",
            "Epoch 165/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9953 - val_loss: 0.6041 - val_accuracy: 0.9279\n",
            "Epoch 166/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9878 - val_loss: 0.6341 - val_accuracy: 0.9203\n",
            "Epoch 167/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9850 - val_loss: 0.6811 - val_accuracy: 0.9203\n",
            "Epoch 168/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.9878 - val_loss: 0.6266 - val_accuracy: 0.9089\n",
            "Epoch 169/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9972 - val_loss: 0.6416 - val_accuracy: 0.9127\n",
            "Epoch 170/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.6231 - val_accuracy: 0.9108\n",
            "Epoch 171/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6268 - val_accuracy: 0.9108\n",
            "Epoch 172/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6292 - val_accuracy: 0.9108\n",
            "Epoch 173/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6322 - val_accuracy: 0.9089\n",
            "Epoch 174/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6312 - val_accuracy: 0.9108\n",
            "Epoch 175/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6252 - val_accuracy: 0.9127\n",
            "Epoch 176/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6322 - val_accuracy: 0.9089\n",
            "Epoch 177/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6405 - val_accuracy: 0.9108\n",
            "Epoch 178/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6331 - val_accuracy: 0.9108\n",
            "Epoch 179/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6411 - val_accuracy: 0.9108\n",
            "Epoch 180/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6461 - val_accuracy: 0.9089\n",
            "Epoch 181/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6394 - val_accuracy: 0.9108\n",
            "Epoch 182/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6334 - val_accuracy: 0.9146\n",
            "Epoch 183/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6424 - val_accuracy: 0.9089\n",
            "Epoch 184/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6518 - val_accuracy: 0.9108\n",
            "Epoch 185/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6339 - val_accuracy: 0.9146\n",
            "Epoch 186/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6421 - val_accuracy: 0.9127\n",
            "Epoch 187/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6489 - val_accuracy: 0.9089\n",
            "Epoch 188/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6599 - val_accuracy: 0.9089\n",
            "Epoch 189/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6471 - val_accuracy: 0.9089\n",
            "Epoch 190/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6467 - val_accuracy: 0.9089\n",
            "Epoch 191/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6529 - val_accuracy: 0.9108\n",
            "Epoch 192/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6495 - val_accuracy: 0.9146\n",
            "Epoch 193/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.6474 - val_accuracy: 0.9108\n",
            "Epoch 194/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6822 - val_accuracy: 0.9127\n",
            "Epoch 195/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9972 - val_loss: 0.6754 - val_accuracy: 0.9127\n",
            "Epoch 196/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.6457 - val_accuracy: 0.9108\n",
            "Epoch 197/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.9878 - val_loss: 0.6649 - val_accuracy: 0.9146\n",
            "Epoch 198/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.6398 - val_accuracy: 0.9108\n",
            "Epoch 199/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.6609 - val_accuracy: 0.9146\n",
            "Epoch 200/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.6512 - val_accuracy: 0.9013\n",
            "Epoch 201/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.6238 - val_accuracy: 0.9146\n",
            "Epoch 202/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6287 - val_accuracy: 0.9089\n",
            "Epoch 203/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6364 - val_accuracy: 0.9070\n",
            "Epoch 204/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6478 - val_accuracy: 0.9127\n",
            "Epoch 205/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6527 - val_accuracy: 0.9108\n",
            "Epoch 206/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6505 - val_accuracy: 0.9089\n",
            "Epoch 207/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6645 - val_accuracy: 0.9108\n",
            "Epoch 208/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6720 - val_accuracy: 0.9089\n",
            "Epoch 209/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6685 - val_accuracy: 0.9127\n",
            "Epoch 210/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6726 - val_accuracy: 0.9108\n",
            "Epoch 211/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 9.9828e-04 - accuracy: 1.0000 - val_loss: 0.6713 - val_accuracy: 0.9070\n",
            "Epoch 212/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6759 - val_accuracy: 0.9108\n",
            "Epoch 213/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 9.5913e-04 - accuracy: 1.0000 - val_loss: 0.6816 - val_accuracy: 0.9108\n",
            "Epoch 214/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 9.0622e-04 - accuracy: 1.0000 - val_loss: 0.6854 - val_accuracy: 0.9108\n",
            "Epoch 215/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 8.7530e-04 - accuracy: 1.0000 - val_loss: 0.6877 - val_accuracy: 0.9127\n",
            "Epoch 216/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 8.8770e-04 - accuracy: 1.0000 - val_loss: 0.6939 - val_accuracy: 0.9108\n",
            "Epoch 217/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 9.0371e-04 - accuracy: 1.0000 - val_loss: 0.6918 - val_accuracy: 0.9127\n",
            "Epoch 218/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 8.1626e-04 - accuracy: 1.0000 - val_loss: 0.6939 - val_accuracy: 0.9146\n",
            "Epoch 219/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.7754e-04 - accuracy: 1.0000 - val_loss: 0.7020 - val_accuracy: 0.9127\n",
            "Epoch 220/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 9.7813e-04 - accuracy: 1.0000 - val_loss: 0.7098 - val_accuracy: 0.9089\n",
            "Epoch 221/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6987 - val_accuracy: 0.9146\n",
            "Epoch 222/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.8789e-04 - accuracy: 1.0000 - val_loss: 0.7092 - val_accuracy: 0.9127\n",
            "Epoch 223/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.0466e-04 - accuracy: 1.0000 - val_loss: 0.7061 - val_accuracy: 0.9127\n",
            "Epoch 224/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.3686e-04 - accuracy: 1.0000 - val_loss: 0.7122 - val_accuracy: 0.9146\n",
            "Epoch 225/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.7174e-04 - accuracy: 1.0000 - val_loss: 0.7164 - val_accuracy: 0.9146\n",
            "Epoch 226/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.6195e-04 - accuracy: 1.0000 - val_loss: 0.7176 - val_accuracy: 0.9146\n",
            "Epoch 227/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.7849e-04 - accuracy: 1.0000 - val_loss: 0.7228 - val_accuracy: 0.9146\n",
            "Epoch 228/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.1507e-04 - accuracy: 1.0000 - val_loss: 0.7275 - val_accuracy: 0.9146\n",
            "Epoch 229/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.8840e-04 - accuracy: 1.0000 - val_loss: 0.7242 - val_accuracy: 0.9127\n",
            "Epoch 230/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.9727e-04 - accuracy: 1.0000 - val_loss: 0.7323 - val_accuracy: 0.9146\n",
            "Epoch 231/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.4705e-04 - accuracy: 1.0000 - val_loss: 0.7404 - val_accuracy: 0.9146\n",
            "Epoch 232/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.5845e-04 - accuracy: 1.0000 - val_loss: 0.7353 - val_accuracy: 0.9146\n",
            "Epoch 233/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.6464e-04 - accuracy: 1.0000 - val_loss: 0.7317 - val_accuracy: 0.9089\n",
            "Epoch 234/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.2591e-04 - accuracy: 1.0000 - val_loss: 0.7373 - val_accuracy: 0.9146\n",
            "Epoch 235/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 8.4437e-04 - accuracy: 1.0000 - val_loss: 0.7554 - val_accuracy: 0.9108\n",
            "Epoch 236/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.6466e-04 - accuracy: 1.0000 - val_loss: 0.7383 - val_accuracy: 0.9108\n",
            "Epoch 237/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 0.7715 - val_accuracy: 0.9146\n",
            "Epoch 238/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.9916 - val_loss: 0.7825 - val_accuracy: 0.9146\n",
            "Epoch 239/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9869 - val_loss: 0.6996 - val_accuracy: 0.9165\n",
            "Epoch 240/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.6804 - val_accuracy: 0.9146\n",
            "Epoch 241/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6945 - val_accuracy: 0.9089\n",
            "Epoch 242/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6816 - val_accuracy: 0.9146\n",
            "Epoch 243/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6858 - val_accuracy: 0.9127\n",
            "Epoch 244/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 9.4325e-04 - accuracy: 1.0000 - val_loss: 0.6850 - val_accuracy: 0.9146\n",
            "Epoch 245/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 9.0142e-04 - accuracy: 1.0000 - val_loss: 0.6893 - val_accuracy: 0.9127\n",
            "Epoch 246/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 8.6017e-04 - accuracy: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.9146\n",
            "Epoch 247/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 8.4494e-04 - accuracy: 1.0000 - val_loss: 0.6911 - val_accuracy: 0.9146\n",
            "Epoch 248/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.7652e-04 - accuracy: 1.0000 - val_loss: 0.6975 - val_accuracy: 0.9127\n",
            "Epoch 249/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.4765e-04 - accuracy: 1.0000 - val_loss: 0.7023 - val_accuracy: 0.9127\n",
            "Epoch 250/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.5455e-04 - accuracy: 1.0000 - val_loss: 0.7035 - val_accuracy: 0.9127\n",
            "Epoch 251/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.2701e-04 - accuracy: 1.0000 - val_loss: 0.7024 - val_accuracy: 0.9127\n",
            "Epoch 252/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.0498e-04 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 0.9127\n",
            "Epoch 253/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.6304e-04 - accuracy: 1.0000 - val_loss: 0.7026 - val_accuracy: 0.9127\n",
            "Epoch 254/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.9884e-04 - accuracy: 1.0000 - val_loss: 0.7043 - val_accuracy: 0.9127\n",
            "Epoch 255/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.6650e-04 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.9127\n",
            "Epoch 256/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.2020e-04 - accuracy: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.9127\n",
            "Epoch 257/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.5473e-04 - accuracy: 1.0000 - val_loss: 0.7089 - val_accuracy: 0.9127\n",
            "Epoch 258/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.5065e-04 - accuracy: 1.0000 - val_loss: 0.7124 - val_accuracy: 0.9127\n",
            "Epoch 259/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.8194e-04 - accuracy: 1.0000 - val_loss: 0.7187 - val_accuracy: 0.9127\n",
            "Epoch 260/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.2805e-04 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.9165\n",
            "Epoch 261/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.9963 - val_loss: 0.7815 - val_accuracy: 0.9127\n",
            "Epoch 262/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9972 - val_loss: 0.7256 - val_accuracy: 0.9222\n",
            "Epoch 263/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.6919 - val_accuracy: 0.9127\n",
            "Epoch 264/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9897 - val_loss: 0.7167 - val_accuracy: 0.9127\n",
            "Epoch 265/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9944 - val_loss: 0.7048 - val_accuracy: 0.9184\n",
            "Epoch 266/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.7035 - val_accuracy: 0.9146\n",
            "Epoch 267/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 9.8736e-04 - accuracy: 1.0000 - val_loss: 0.7165 - val_accuracy: 0.9108\n",
            "Epoch 268/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.3984e-04 - accuracy: 1.0000 - val_loss: 0.7158 - val_accuracy: 0.9127\n",
            "Epoch 269/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.7315e-04 - accuracy: 1.0000 - val_loss: 0.7197 - val_accuracy: 0.9108\n",
            "Epoch 270/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.4896e-04 - accuracy: 1.0000 - val_loss: 0.7258 - val_accuracy: 0.9089\n",
            "Epoch 271/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.2794e-04 - accuracy: 1.0000 - val_loss: 0.7294 - val_accuracy: 0.9089\n",
            "Epoch 272/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.6652e-04 - accuracy: 1.0000 - val_loss: 0.7297 - val_accuracy: 0.9108\n",
            "Epoch 273/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.4947e-04 - accuracy: 1.0000 - val_loss: 0.7316 - val_accuracy: 0.9127\n",
            "Epoch 274/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.3688e-04 - accuracy: 1.0000 - val_loss: 0.7356 - val_accuracy: 0.9127\n",
            "Epoch 275/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.9464e-04 - accuracy: 1.0000 - val_loss: 0.7370 - val_accuracy: 0.9127\n",
            "Epoch 276/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.7604e-04 - accuracy: 1.0000 - val_loss: 0.7377 - val_accuracy: 0.9127\n",
            "Epoch 277/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.8369e-04 - accuracy: 1.0000 - val_loss: 0.7433 - val_accuracy: 0.9127\n",
            "Epoch 278/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.5043e-04 - accuracy: 1.0000 - val_loss: 0.7435 - val_accuracy: 0.9127\n",
            "Epoch 279/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.5984e-04 - accuracy: 1.0000 - val_loss: 0.7430 - val_accuracy: 0.9184\n",
            "Epoch 280/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.3628e-04 - accuracy: 1.0000 - val_loss: 0.7487 - val_accuracy: 0.9127\n",
            "Epoch 281/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.0688e-04 - accuracy: 1.0000 - val_loss: 0.7534 - val_accuracy: 0.9127\n",
            "Epoch 282/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.1637e-04 - accuracy: 1.0000 - val_loss: 0.7578 - val_accuracy: 0.9127\n",
            "Epoch 283/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.8430e-04 - accuracy: 1.0000 - val_loss: 0.7580 - val_accuracy: 0.9146\n",
            "Epoch 284/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.8478e-04 - accuracy: 1.0000 - val_loss: 0.7602 - val_accuracy: 0.9127\n",
            "Epoch 285/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.6022e-04 - accuracy: 1.0000 - val_loss: 0.7634 - val_accuracy: 0.9146\n",
            "Epoch 286/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.5261e-04 - accuracy: 1.0000 - val_loss: 0.7627 - val_accuracy: 0.9165\n",
            "Epoch 287/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.5277e-04 - accuracy: 1.0000 - val_loss: 0.7727 - val_accuracy: 0.9127\n",
            "Epoch 288/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.5259e-04 - accuracy: 1.0000 - val_loss: 0.7687 - val_accuracy: 0.9146\n",
            "Epoch 289/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.3311e-04 - accuracy: 1.0000 - val_loss: 0.7716 - val_accuracy: 0.9165\n",
            "Epoch 290/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.2970e-04 - accuracy: 1.0000 - val_loss: 0.7773 - val_accuracy: 0.9146\n",
            "Epoch 291/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.1444e-04 - accuracy: 1.0000 - val_loss: 0.7771 - val_accuracy: 0.9165\n",
            "Epoch 292/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.9398e-04 - accuracy: 1.0000 - val_loss: 0.7805 - val_accuracy: 0.9165\n",
            "Epoch 293/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.8975e-04 - accuracy: 1.0000 - val_loss: 0.7820 - val_accuracy: 0.9165\n",
            "Epoch 294/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.0180e-04 - accuracy: 1.0000 - val_loss: 0.7800 - val_accuracy: 0.9165\n",
            "Epoch 295/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.9683e-04 - accuracy: 1.0000 - val_loss: 0.7860 - val_accuracy: 0.9165\n",
            "Epoch 296/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.6785e-04 - accuracy: 1.0000 - val_loss: 0.7917 - val_accuracy: 0.9165\n",
            "Epoch 297/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.5216e-04 - accuracy: 1.0000 - val_loss: 0.7912 - val_accuracy: 0.9165\n",
            "Epoch 298/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.7222e-04 - accuracy: 1.0000 - val_loss: 0.7950 - val_accuracy: 0.9165\n",
            "Epoch 299/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.9301e-04 - accuracy: 1.0000 - val_loss: 0.8043 - val_accuracy: 0.9165\n",
            "Epoch 300/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8484 - val_accuracy: 0.9146\n",
            "Epoch 301/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0794 - accuracy: 0.9869 - val_loss: 1.0524 - val_accuracy: 0.9146\n",
            "Epoch 302/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9869 - val_loss: 0.7853 - val_accuracy: 0.9203\n",
            "Epoch 303/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.8340 - val_accuracy: 0.9146\n",
            "Epoch 304/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8077 - val_accuracy: 0.9165\n",
            "Epoch 305/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7989 - val_accuracy: 0.9146\n",
            "Epoch 306/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.5788e-04 - accuracy: 1.0000 - val_loss: 0.8014 - val_accuracy: 0.9146\n",
            "Epoch 307/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.2095e-04 - accuracy: 1.0000 - val_loss: 0.8025 - val_accuracy: 0.9165\n",
            "Epoch 308/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.7162e-04 - accuracy: 1.0000 - val_loss: 0.8022 - val_accuracy: 0.9165\n",
            "Epoch 309/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.4103e-04 - accuracy: 1.0000 - val_loss: 0.8049 - val_accuracy: 0.9165\n",
            "Epoch 310/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.0844e-04 - accuracy: 1.0000 - val_loss: 0.8033 - val_accuracy: 0.9146\n",
            "Epoch 311/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.9282e-04 - accuracy: 1.0000 - val_loss: 0.8040 - val_accuracy: 0.9146\n",
            "Epoch 312/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.7119e-04 - accuracy: 1.0000 - val_loss: 0.8073 - val_accuracy: 0.9146\n",
            "Epoch 313/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.5173e-04 - accuracy: 1.0000 - val_loss: 0.8085 - val_accuracy: 0.9146\n",
            "Epoch 314/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.3281e-04 - accuracy: 1.0000 - val_loss: 0.8077 - val_accuracy: 0.9146\n",
            "Epoch 315/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.1367e-04 - accuracy: 1.0000 - val_loss: 0.8116 - val_accuracy: 0.9146\n",
            "Epoch 316/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.0775e-04 - accuracy: 1.0000 - val_loss: 0.8141 - val_accuracy: 0.9146\n",
            "Epoch 317/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.9143e-04 - accuracy: 1.0000 - val_loss: 0.8139 - val_accuracy: 0.9146\n",
            "Epoch 318/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.7902e-04 - accuracy: 1.0000 - val_loss: 0.8188 - val_accuracy: 0.9146\n",
            "Epoch 319/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.8023e-04 - accuracy: 1.0000 - val_loss: 0.8168 - val_accuracy: 0.9146\n",
            "Epoch 320/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.6600e-04 - accuracy: 1.0000 - val_loss: 0.8207 - val_accuracy: 0.9146\n",
            "Epoch 321/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.4698e-04 - accuracy: 1.0000 - val_loss: 0.8205 - val_accuracy: 0.9146\n",
            "Epoch 322/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.3936e-04 - accuracy: 1.0000 - val_loss: 0.8243 - val_accuracy: 0.9146\n",
            "Epoch 323/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.4590e-04 - accuracy: 1.0000 - val_loss: 0.8260 - val_accuracy: 0.9146\n",
            "Epoch 324/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.2887e-04 - accuracy: 1.0000 - val_loss: 0.8213 - val_accuracy: 0.9146\n",
            "Epoch 325/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.2066e-04 - accuracy: 1.0000 - val_loss: 0.8324 - val_accuracy: 0.9146\n",
            "Epoch 326/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.3243e-04 - accuracy: 1.0000 - val_loss: 0.8255 - val_accuracy: 0.9146\n",
            "Epoch 327/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.3031e-04 - accuracy: 1.0000 - val_loss: 0.8294 - val_accuracy: 0.9146\n",
            "Epoch 328/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.0204e-04 - accuracy: 1.0000 - val_loss: 0.8326 - val_accuracy: 0.9146\n",
            "Epoch 329/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.9433e-04 - accuracy: 1.0000 - val_loss: 0.8388 - val_accuracy: 0.9146\n",
            "Epoch 330/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.8676e-04 - accuracy: 1.0000 - val_loss: 0.8319 - val_accuracy: 0.9127\n",
            "Epoch 331/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.8107e-04 - accuracy: 1.0000 - val_loss: 0.8425 - val_accuracy: 0.9146\n",
            "Epoch 332/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.8914e-04 - accuracy: 1.0000 - val_loss: 0.8413 - val_accuracy: 0.9127\n",
            "Epoch 333/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.6703e-04 - accuracy: 1.0000 - val_loss: 0.8380 - val_accuracy: 0.9127\n",
            "Epoch 334/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.9193e-04 - accuracy: 1.0000 - val_loss: 0.8429 - val_accuracy: 0.9127\n",
            "Epoch 335/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.6107e-04 - accuracy: 1.0000 - val_loss: 0.8467 - val_accuracy: 0.9127\n",
            "Epoch 336/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.8346e-04 - accuracy: 1.0000 - val_loss: 0.8480 - val_accuracy: 0.9127\n",
            "Epoch 337/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.5179e-04 - accuracy: 1.0000 - val_loss: 0.8512 - val_accuracy: 0.9127\n",
            "Epoch 338/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.4897e-04 - accuracy: 1.0000 - val_loss: 0.8496 - val_accuracy: 0.9127\n",
            "Epoch 339/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.4224e-04 - accuracy: 1.0000 - val_loss: 0.8562 - val_accuracy: 0.9127\n",
            "Epoch 340/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.4074e-04 - accuracy: 1.0000 - val_loss: 0.8525 - val_accuracy: 0.9127\n",
            "Epoch 341/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.6727e-04 - accuracy: 1.0000 - val_loss: 0.8522 - val_accuracy: 0.9127\n",
            "Epoch 342/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.4874e-04 - accuracy: 1.0000 - val_loss: 0.8650 - val_accuracy: 0.9127\n",
            "Epoch 343/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.7294e-04 - accuracy: 1.0000 - val_loss: 0.8607 - val_accuracy: 0.9127\n",
            "Epoch 344/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.2128e-04 - accuracy: 1.0000 - val_loss: 0.8598 - val_accuracy: 0.9127\n",
            "Epoch 345/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.3002e-04 - accuracy: 1.0000 - val_loss: 0.8601 - val_accuracy: 0.9127\n",
            "Epoch 346/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.0614e-04 - accuracy: 1.0000 - val_loss: 0.8746 - val_accuracy: 0.9127\n",
            "Epoch 347/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.2352e-04 - accuracy: 1.0000 - val_loss: 0.8702 - val_accuracy: 0.9127\n",
            "Epoch 348/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.1206e-04 - accuracy: 1.0000 - val_loss: 0.8721 - val_accuracy: 0.9127\n",
            "Epoch 349/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.9033e-04 - accuracy: 1.0000 - val_loss: 0.8632 - val_accuracy: 0.9108\n",
            "Epoch 350/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.5276e-04 - accuracy: 1.0000 - val_loss: 0.8780 - val_accuracy: 0.9127\n",
            "Epoch 351/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.9644e-04 - accuracy: 1.0000 - val_loss: 0.8600 - val_accuracy: 0.9108\n",
            "Epoch 352/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9916 - val_loss: 1.1500 - val_accuracy: 0.8975\n",
            "Epoch 353/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0896 - accuracy: 0.9859 - val_loss: 0.8918 - val_accuracy: 0.9089\n",
            "Epoch 354/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9859 - val_loss: 0.6611 - val_accuracy: 0.9127\n",
            "Epoch 355/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.7242 - val_accuracy: 0.9146\n",
            "Epoch 356/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7115 - val_accuracy: 0.9146\n",
            "Epoch 357/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7091 - val_accuracy: 0.9146\n",
            "Epoch 358/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7074 - val_accuracy: 0.9146\n",
            "Epoch 359/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 9.2183e-04 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.9146\n",
            "Epoch 360/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 8.3276e-04 - accuracy: 1.0000 - val_loss: 0.7108 - val_accuracy: 0.9146\n",
            "Epoch 361/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.6722e-04 - accuracy: 1.0000 - val_loss: 0.7105 - val_accuracy: 0.9146\n",
            "Epoch 362/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.1229e-04 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.9146\n",
            "Epoch 363/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.7932e-04 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.9146\n",
            "Epoch 364/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.4146e-04 - accuracy: 1.0000 - val_loss: 0.7155 - val_accuracy: 0.9146\n",
            "Epoch 365/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.9711e-04 - accuracy: 1.0000 - val_loss: 0.7154 - val_accuracy: 0.9146\n",
            "Epoch 366/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.5882e-04 - accuracy: 1.0000 - val_loss: 0.7162 - val_accuracy: 0.9127\n",
            "Epoch 367/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.4017e-04 - accuracy: 1.0000 - val_loss: 0.7187 - val_accuracy: 0.9127\n",
            "Epoch 368/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.9991e-04 - accuracy: 1.0000 - val_loss: 0.7198 - val_accuracy: 0.9127\n",
            "Epoch 369/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.8369e-04 - accuracy: 1.0000 - val_loss: 0.7203 - val_accuracy: 0.9127\n",
            "Epoch 370/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.6704e-04 - accuracy: 1.0000 - val_loss: 0.7199 - val_accuracy: 0.9146\n",
            "Epoch 371/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.4217e-04 - accuracy: 1.0000 - val_loss: 0.7211 - val_accuracy: 0.9146\n",
            "Epoch 372/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.1456e-04 - accuracy: 1.0000 - val_loss: 0.7238 - val_accuracy: 0.9146\n",
            "Epoch 373/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.0414e-04 - accuracy: 1.0000 - val_loss: 0.7275 - val_accuracy: 0.9146\n",
            "Epoch 374/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.8248e-04 - accuracy: 1.0000 - val_loss: 0.7286 - val_accuracy: 0.9146\n",
            "Epoch 375/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.7153e-04 - accuracy: 1.0000 - val_loss: 0.7302 - val_accuracy: 0.9146\n",
            "Epoch 376/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.6118e-04 - accuracy: 1.0000 - val_loss: 0.7301 - val_accuracy: 0.9127\n",
            "Epoch 377/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.4505e-04 - accuracy: 1.0000 - val_loss: 0.7335 - val_accuracy: 0.9127\n",
            "Epoch 378/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.2992e-04 - accuracy: 1.0000 - val_loss: 0.7331 - val_accuracy: 0.9127\n",
            "Epoch 379/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.2274e-04 - accuracy: 1.0000 - val_loss: 0.7303 - val_accuracy: 0.9146\n",
            "Epoch 380/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.1124e-04 - accuracy: 1.0000 - val_loss: 0.7383 - val_accuracy: 0.9127\n",
            "Epoch 381/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.9994e-04 - accuracy: 1.0000 - val_loss: 0.7416 - val_accuracy: 0.9127\n",
            "Epoch 382/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.9075e-04 - accuracy: 1.0000 - val_loss: 0.7421 - val_accuracy: 0.9146\n",
            "Epoch 383/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.8385e-04 - accuracy: 1.0000 - val_loss: 0.7374 - val_accuracy: 0.9146\n",
            "Epoch 384/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.7637e-04 - accuracy: 1.0000 - val_loss: 0.7408 - val_accuracy: 0.9146\n",
            "Epoch 385/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.6412e-04 - accuracy: 1.0000 - val_loss: 0.7447 - val_accuracy: 0.9146\n",
            "Epoch 386/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.5963e-04 - accuracy: 1.0000 - val_loss: 0.7507 - val_accuracy: 0.9127\n",
            "Epoch 387/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.5620e-04 - accuracy: 1.0000 - val_loss: 0.7499 - val_accuracy: 0.9146\n",
            "Epoch 388/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.4736e-04 - accuracy: 1.0000 - val_loss: 0.7515 - val_accuracy: 0.9146\n",
            "Epoch 389/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.3904e-04 - accuracy: 1.0000 - val_loss: 0.7500 - val_accuracy: 0.9146\n",
            "Epoch 390/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.3029e-04 - accuracy: 1.0000 - val_loss: 0.7565 - val_accuracy: 0.9165\n",
            "Epoch 391/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.3127e-04 - accuracy: 1.0000 - val_loss: 0.7562 - val_accuracy: 0.9146\n",
            "Epoch 392/1000\n",
            "67/67 [==============================] - 1s 9ms/step - loss: 2.1675e-04 - accuracy: 1.0000 - val_loss: 0.7566 - val_accuracy: 0.9146\n",
            "Epoch 393/1000\n",
            "67/67 [==============================] - 0s 5ms/step - loss: 2.2382e-04 - accuracy: 1.0000 - val_loss: 0.7664 - val_accuracy: 0.9108\n",
            "Epoch 394/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.3306e-04 - accuracy: 1.0000 - val_loss: 0.7725 - val_accuracy: 0.9146\n",
            "Epoch 395/1000\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 2.9076e-04 - accuracy: 1.0000 - val_loss: 0.7629 - val_accuracy: 0.9127\n",
            "Epoch 396/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.1366e-04 - accuracy: 1.0000 - val_loss: 0.7683 - val_accuracy: 0.9108\n",
            "Epoch 397/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.1016e-04 - accuracy: 1.0000 - val_loss: 0.7742 - val_accuracy: 0.9089\n",
            "Epoch 398/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.3993e-04 - accuracy: 1.0000 - val_loss: 0.7704 - val_accuracy: 0.9127\n",
            "Epoch 399/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.8451e-04 - accuracy: 1.0000 - val_loss: 0.7699 - val_accuracy: 0.9127\n",
            "Epoch 400/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.7741e-04 - accuracy: 1.0000 - val_loss: 0.7790 - val_accuracy: 0.9127\n",
            "Epoch 401/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.9044e-04 - accuracy: 1.0000 - val_loss: 0.7734 - val_accuracy: 0.9127\n",
            "Epoch 402/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.7604e-04 - accuracy: 1.0000 - val_loss: 0.7751 - val_accuracy: 0.9127\n",
            "Epoch 403/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.8529e-04 - accuracy: 1.0000 - val_loss: 0.7719 - val_accuracy: 0.9127\n",
            "Epoch 404/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.7024e-04 - accuracy: 1.0000 - val_loss: 0.7856 - val_accuracy: 0.9127\n",
            "Epoch 405/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.6360e-04 - accuracy: 1.0000 - val_loss: 0.7816 - val_accuracy: 0.9127\n",
            "Epoch 406/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.5632e-04 - accuracy: 1.0000 - val_loss: 0.7859 - val_accuracy: 0.9127\n",
            "Epoch 407/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.6387e-04 - accuracy: 1.0000 - val_loss: 0.7890 - val_accuracy: 0.9127\n",
            "Epoch 408/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.6777e-04 - accuracy: 1.0000 - val_loss: 0.7887 - val_accuracy: 0.9127\n",
            "Epoch 409/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.5507e-04 - accuracy: 1.0000 - val_loss: 0.7850 - val_accuracy: 0.9127\n",
            "Epoch 410/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.4990e-04 - accuracy: 1.0000 - val_loss: 0.7947 - val_accuracy: 0.9127\n",
            "Epoch 411/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.5536e-04 - accuracy: 1.0000 - val_loss: 0.7970 - val_accuracy: 0.9127\n",
            "Epoch 412/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.3573e-04 - accuracy: 1.0000 - val_loss: 0.7932 - val_accuracy: 0.9146\n",
            "Epoch 413/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.3386e-04 - accuracy: 1.0000 - val_loss: 0.7950 - val_accuracy: 0.9146\n",
            "Epoch 414/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.3727e-04 - accuracy: 1.0000 - val_loss: 0.8038 - val_accuracy: 0.9127\n",
            "Epoch 415/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.4060e-04 - accuracy: 1.0000 - val_loss: 0.8018 - val_accuracy: 0.9127\n",
            "Epoch 416/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.5664e-04 - accuracy: 1.0000 - val_loss: 0.8051 - val_accuracy: 0.9184\n",
            "Epoch 417/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.3009e-04 - accuracy: 1.0000 - val_loss: 0.8427 - val_accuracy: 0.9146\n",
            "Epoch 418/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9972 - val_loss: 0.7691 - val_accuracy: 0.9146\n",
            "Epoch 419/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9878 - val_loss: 0.7642 - val_accuracy: 0.9222\n",
            "Epoch 420/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.9916 - val_loss: 0.7262 - val_accuracy: 0.9184\n",
            "Epoch 421/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 0.9944 - val_loss: 0.8303 - val_accuracy: 0.9146\n",
            "Epoch 422/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9878 - val_loss: 0.9364 - val_accuracy: 0.9089\n",
            "Epoch 423/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9981 - val_loss: 0.8186 - val_accuracy: 0.9108\n",
            "Epoch 424/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7891 - val_accuracy: 0.9089\n",
            "Epoch 425/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 9.5371e-04 - accuracy: 1.0000 - val_loss: 0.8055 - val_accuracy: 0.9089\n",
            "Epoch 426/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 7.0005e-04 - accuracy: 1.0000 - val_loss: 0.8088 - val_accuracy: 0.9089\n",
            "Epoch 427/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.2340e-04 - accuracy: 1.0000 - val_loss: 0.8109 - val_accuracy: 0.9108\n",
            "Epoch 428/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.8298e-04 - accuracy: 1.0000 - val_loss: 0.8158 - val_accuracy: 0.9108\n",
            "Epoch 429/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.3034e-04 - accuracy: 1.0000 - val_loss: 0.8160 - val_accuracy: 0.9108\n",
            "Epoch 430/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.9090e-04 - accuracy: 1.0000 - val_loss: 0.8197 - val_accuracy: 0.9108\n",
            "Epoch 431/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.5270e-04 - accuracy: 1.0000 - val_loss: 0.8219 - val_accuracy: 0.9108\n",
            "Epoch 432/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.2941e-04 - accuracy: 1.0000 - val_loss: 0.8244 - val_accuracy: 0.9108\n",
            "Epoch 433/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.1123e-04 - accuracy: 1.0000 - val_loss: 0.8261 - val_accuracy: 0.9108\n",
            "Epoch 434/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.8831e-04 - accuracy: 1.0000 - val_loss: 0.8282 - val_accuracy: 0.9108\n",
            "Epoch 435/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.6858e-04 - accuracy: 1.0000 - val_loss: 0.8289 - val_accuracy: 0.9108\n",
            "Epoch 436/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.5456e-04 - accuracy: 1.0000 - val_loss: 0.8307 - val_accuracy: 0.9108\n",
            "Epoch 437/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.3306e-04 - accuracy: 1.0000 - val_loss: 0.8351 - val_accuracy: 0.9108\n",
            "Epoch 438/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.1985e-04 - accuracy: 1.0000 - val_loss: 0.8362 - val_accuracy: 0.9108\n",
            "Epoch 439/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.0668e-04 - accuracy: 1.0000 - val_loss: 0.8363 - val_accuracy: 0.9108\n",
            "Epoch 440/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.9905e-04 - accuracy: 1.0000 - val_loss: 0.8390 - val_accuracy: 0.9108\n",
            "Epoch 441/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.8463e-04 - accuracy: 1.0000 - val_loss: 0.8393 - val_accuracy: 0.9108\n",
            "Epoch 442/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.7832e-04 - accuracy: 1.0000 - val_loss: 0.8404 - val_accuracy: 0.9108\n",
            "Epoch 443/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.6114e-04 - accuracy: 1.0000 - val_loss: 0.8433 - val_accuracy: 0.9108\n",
            "Epoch 444/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.5339e-04 - accuracy: 1.0000 - val_loss: 0.8448 - val_accuracy: 0.9108\n",
            "Epoch 445/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.5028e-04 - accuracy: 1.0000 - val_loss: 0.8443 - val_accuracy: 0.9108\n",
            "Epoch 446/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.4015e-04 - accuracy: 1.0000 - val_loss: 0.8465 - val_accuracy: 0.9108\n",
            "Epoch 447/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.3084e-04 - accuracy: 1.0000 - val_loss: 0.8480 - val_accuracy: 0.9108\n",
            "Epoch 448/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.4451e-04 - accuracy: 1.0000 - val_loss: 0.8472 - val_accuracy: 0.9108\n",
            "Epoch 449/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.3579e-04 - accuracy: 1.0000 - val_loss: 0.8520 - val_accuracy: 0.9108\n",
            "Epoch 450/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.0768e-04 - accuracy: 1.0000 - val_loss: 0.8561 - val_accuracy: 0.9108\n",
            "Epoch 451/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.0573e-04 - accuracy: 1.0000 - val_loss: 0.8560 - val_accuracy: 0.9108\n",
            "Epoch 452/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.9999e-04 - accuracy: 1.0000 - val_loss: 0.8610 - val_accuracy: 0.9108\n",
            "Epoch 453/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.0230e-04 - accuracy: 1.0000 - val_loss: 0.8592 - val_accuracy: 0.9108\n",
            "Epoch 454/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.9048e-04 - accuracy: 1.0000 - val_loss: 0.8585 - val_accuracy: 0.9108\n",
            "Epoch 455/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.8534e-04 - accuracy: 1.0000 - val_loss: 0.8641 - val_accuracy: 0.9108\n",
            "Epoch 456/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.8953e-04 - accuracy: 1.0000 - val_loss: 0.8635 - val_accuracy: 0.9108\n",
            "Epoch 457/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.8295e-04 - accuracy: 1.0000 - val_loss: 0.8693 - val_accuracy: 0.9108\n",
            "Epoch 458/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.7145e-04 - accuracy: 1.0000 - val_loss: 0.8694 - val_accuracy: 0.9108\n",
            "Epoch 459/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.6760e-04 - accuracy: 1.0000 - val_loss: 0.8701 - val_accuracy: 0.9108\n",
            "Epoch 460/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.7007e-04 - accuracy: 1.0000 - val_loss: 0.8685 - val_accuracy: 0.9108\n",
            "Epoch 461/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.6103e-04 - accuracy: 1.0000 - val_loss: 0.8742 - val_accuracy: 0.9108\n",
            "Epoch 462/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.5821e-04 - accuracy: 1.0000 - val_loss: 0.8763 - val_accuracy: 0.9108\n",
            "Epoch 463/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.6211e-04 - accuracy: 1.0000 - val_loss: 0.8836 - val_accuracy: 0.9108\n",
            "Epoch 464/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.7273e-04 - accuracy: 1.0000 - val_loss: 0.8836 - val_accuracy: 0.9108\n",
            "Epoch 465/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.5753e-04 - accuracy: 1.0000 - val_loss: 0.8805 - val_accuracy: 0.9108\n",
            "Epoch 466/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.5489e-04 - accuracy: 1.0000 - val_loss: 0.8884 - val_accuracy: 0.9108\n",
            "Epoch 467/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.3802e-04 - accuracy: 1.0000 - val_loss: 0.8807 - val_accuracy: 0.9108\n",
            "Epoch 468/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.4192e-04 - accuracy: 1.0000 - val_loss: 0.8913 - val_accuracy: 0.9108\n",
            "Epoch 469/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.4004e-04 - accuracy: 1.0000 - val_loss: 0.8895 - val_accuracy: 0.9108\n",
            "Epoch 470/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.3946e-04 - accuracy: 1.0000 - val_loss: 0.8981 - val_accuracy: 0.9089\n",
            "Epoch 471/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.5042e-04 - accuracy: 1.0000 - val_loss: 0.8975 - val_accuracy: 0.9108\n",
            "Epoch 472/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.7742e-04 - accuracy: 1.0000 - val_loss: 0.9135 - val_accuracy: 0.9070\n",
            "Epoch 473/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 0.9944 - val_loss: 0.8728 - val_accuracy: 0.9032\n",
            "Epoch 474/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9869 - val_loss: 0.7594 - val_accuracy: 0.9108\n",
            "Epoch 475/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9953 - val_loss: 0.7947 - val_accuracy: 0.9089\n",
            "Epoch 476/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8235 - val_accuracy: 0.9089\n",
            "Epoch 477/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.1816e-04 - accuracy: 1.0000 - val_loss: 0.8212 - val_accuracy: 0.9089\n",
            "Epoch 478/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.7812e-04 - accuracy: 1.0000 - val_loss: 0.8258 - val_accuracy: 0.9089\n",
            "Epoch 479/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.1223e-04 - accuracy: 1.0000 - val_loss: 0.8292 - val_accuracy: 0.9089\n",
            "Epoch 480/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.6989e-04 - accuracy: 1.0000 - val_loss: 0.8320 - val_accuracy: 0.9089\n",
            "Epoch 481/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.4090e-04 - accuracy: 1.0000 - val_loss: 0.8351 - val_accuracy: 0.9089\n",
            "Epoch 482/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.1851e-04 - accuracy: 1.0000 - val_loss: 0.8389 - val_accuracy: 0.9089\n",
            "Epoch 483/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.9665e-04 - accuracy: 1.0000 - val_loss: 0.8414 - val_accuracy: 0.9089\n",
            "Epoch 484/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.7459e-04 - accuracy: 1.0000 - val_loss: 0.8443 - val_accuracy: 0.9089\n",
            "Epoch 485/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.5519e-04 - accuracy: 1.0000 - val_loss: 0.8484 - val_accuracy: 0.9089\n",
            "Epoch 486/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.4683e-04 - accuracy: 1.0000 - val_loss: 0.8502 - val_accuracy: 0.9089\n",
            "Epoch 487/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.3671e-04 - accuracy: 1.0000 - val_loss: 0.8542 - val_accuracy: 0.9089\n",
            "Epoch 488/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.2607e-04 - accuracy: 1.0000 - val_loss: 0.8564 - val_accuracy: 0.9089\n",
            "Epoch 489/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.1234e-04 - accuracy: 1.0000 - val_loss: 0.8579 - val_accuracy: 0.9089\n",
            "Epoch 490/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.0292e-04 - accuracy: 1.0000 - val_loss: 0.8623 - val_accuracy: 0.9089\n",
            "Epoch 491/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.9401e-04 - accuracy: 1.0000 - val_loss: 0.8649 - val_accuracy: 0.9089\n",
            "Epoch 492/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.8559e-04 - accuracy: 1.0000 - val_loss: 0.8694 - val_accuracy: 0.9089\n",
            "Epoch 493/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.7695e-04 - accuracy: 1.0000 - val_loss: 0.8714 - val_accuracy: 0.9089\n",
            "Epoch 494/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.7058e-04 - accuracy: 1.0000 - val_loss: 0.8759 - val_accuracy: 0.9089\n",
            "Epoch 495/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.6854e-04 - accuracy: 1.0000 - val_loss: 0.8781 - val_accuracy: 0.9089\n",
            "Epoch 496/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.6584e-04 - accuracy: 1.0000 - val_loss: 0.8788 - val_accuracy: 0.9089\n",
            "Epoch 497/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.5648e-04 - accuracy: 1.0000 - val_loss: 0.8820 - val_accuracy: 0.9089\n",
            "Epoch 498/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.5309e-04 - accuracy: 1.0000 - val_loss: 0.8875 - val_accuracy: 0.9089\n",
            "Epoch 499/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.5036e-04 - accuracy: 1.0000 - val_loss: 0.8897 - val_accuracy: 0.9089\n",
            "Epoch 500/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.4528e-04 - accuracy: 1.0000 - val_loss: 0.8928 - val_accuracy: 0.9089\n",
            "Epoch 501/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.3732e-04 - accuracy: 1.0000 - val_loss: 0.8922 - val_accuracy: 0.9089\n",
            "Epoch 502/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.3350e-04 - accuracy: 1.0000 - val_loss: 0.8990 - val_accuracy: 0.9089\n",
            "Epoch 503/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.2790e-04 - accuracy: 1.0000 - val_loss: 0.8983 - val_accuracy: 0.9089\n",
            "Epoch 504/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.2224e-04 - accuracy: 1.0000 - val_loss: 0.9012 - val_accuracy: 0.9089\n",
            "Epoch 505/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.2324e-04 - accuracy: 1.0000 - val_loss: 0.9052 - val_accuracy: 0.9089\n",
            "Epoch 506/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.2242e-04 - accuracy: 1.0000 - val_loss: 0.9072 - val_accuracy: 0.9089\n",
            "Epoch 507/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.2333e-04 - accuracy: 1.0000 - val_loss: 0.9105 - val_accuracy: 0.9089\n",
            "Epoch 508/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.1146e-04 - accuracy: 1.0000 - val_loss: 0.9085 - val_accuracy: 0.9089\n",
            "Epoch 509/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.1682e-04 - accuracy: 1.0000 - val_loss: 0.9100 - val_accuracy: 0.9089\n",
            "Epoch 510/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.1664e-04 - accuracy: 1.0000 - val_loss: 0.9182 - val_accuracy: 0.9089\n",
            "Epoch 511/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.1324e-04 - accuracy: 1.0000 - val_loss: 0.9113 - val_accuracy: 0.9089\n",
            "Epoch 512/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.1898e-04 - accuracy: 1.0000 - val_loss: 0.9224 - val_accuracy: 0.9089\n",
            "Epoch 513/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 9.9320e-05 - accuracy: 1.0000 - val_loss: 0.9208 - val_accuracy: 0.9089\n",
            "Epoch 514/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.1675e-04 - accuracy: 1.0000 - val_loss: 0.9218 - val_accuracy: 0.9089\n",
            "Epoch 515/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.0080e-04 - accuracy: 1.0000 - val_loss: 0.9317 - val_accuracy: 0.9108\n",
            "Epoch 516/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 9.8899e-05 - accuracy: 1.0000 - val_loss: 0.9345 - val_accuracy: 0.9108\n",
            "Epoch 517/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 9.3698e-05 - accuracy: 1.0000 - val_loss: 0.9349 - val_accuracy: 0.9089\n",
            "Epoch 518/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 8.5526e-05 - accuracy: 1.0000 - val_loss: 0.9383 - val_accuracy: 0.9089\n",
            "Epoch 519/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 9.2084e-05 - accuracy: 1.0000 - val_loss: 0.9419 - val_accuracy: 0.9089\n",
            "Epoch 520/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 8.9968e-05 - accuracy: 1.0000 - val_loss: 0.9439 - val_accuracy: 0.9089\n",
            "Epoch 521/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.6341e-05 - accuracy: 1.0000 - val_loss: 0.9443 - val_accuracy: 0.9089\n",
            "Epoch 522/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 8.4536e-05 - accuracy: 1.0000 - val_loss: 0.9523 - val_accuracy: 0.9108\n",
            "Epoch 523/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 9.1149e-05 - accuracy: 1.0000 - val_loss: 0.9529 - val_accuracy: 0.9089\n",
            "Epoch 524/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 7.2652e-05 - accuracy: 1.0000 - val_loss: 0.9512 - val_accuracy: 0.9089\n",
            "Epoch 525/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.0574e-05 - accuracy: 1.0000 - val_loss: 0.9605 - val_accuracy: 0.9108\n",
            "Epoch 526/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.0276e-05 - accuracy: 1.0000 - val_loss: 0.9582 - val_accuracy: 0.9089\n",
            "Epoch 527/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 8.0014e-05 - accuracy: 1.0000 - val_loss: 0.9660 - val_accuracy: 0.9108\n",
            "Epoch 528/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.0230 - accuracy: 0.9972 - val_loss: 0.9135 - val_accuracy: 0.9108\n",
            "Epoch 529/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0783 - accuracy: 0.9841 - val_loss: 0.9296 - val_accuracy: 0.9108\n",
            "Epoch 530/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9878 - val_loss: 0.7022 - val_accuracy: 0.9127\n",
            "Epoch 531/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9953 - val_loss: 0.9121 - val_accuracy: 0.8994\n",
            "Epoch 532/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 0.9944 - val_loss: 0.7661 - val_accuracy: 0.9184\n",
            "Epoch 533/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7242 - val_accuracy: 0.9165\n",
            "Epoch 534/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7342 - val_accuracy: 0.9146\n",
            "Epoch 535/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 9.0897e-04 - accuracy: 1.0000 - val_loss: 0.7350 - val_accuracy: 0.9146\n",
            "Epoch 536/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.7575e-04 - accuracy: 1.0000 - val_loss: 0.7371 - val_accuracy: 0.9146\n",
            "Epoch 537/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.9858e-04 - accuracy: 1.0000 - val_loss: 0.7365 - val_accuracy: 0.9165\n",
            "Epoch 538/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 6.1934e-04 - accuracy: 1.0000 - val_loss: 0.7401 - val_accuracy: 0.9165\n",
            "Epoch 539/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.6737e-04 - accuracy: 1.0000 - val_loss: 0.7425 - val_accuracy: 0.9165\n",
            "Epoch 540/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.2726e-04 - accuracy: 1.0000 - val_loss: 0.7438 - val_accuracy: 0.9165\n",
            "Epoch 541/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.8591e-04 - accuracy: 1.0000 - val_loss: 0.7461 - val_accuracy: 0.9165\n",
            "Epoch 542/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.5178e-04 - accuracy: 1.0000 - val_loss: 0.7490 - val_accuracy: 0.9184\n",
            "Epoch 543/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.3696e-04 - accuracy: 1.0000 - val_loss: 0.7516 - val_accuracy: 0.9165\n",
            "Epoch 544/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.0267e-04 - accuracy: 1.0000 - val_loss: 0.7542 - val_accuracy: 0.9184\n",
            "Epoch 545/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.7498e-04 - accuracy: 1.0000 - val_loss: 0.7552 - val_accuracy: 0.9184\n",
            "Epoch 546/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.5808e-04 - accuracy: 1.0000 - val_loss: 0.7587 - val_accuracy: 0.9184\n",
            "Epoch 547/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.3866e-04 - accuracy: 1.0000 - val_loss: 0.7598 - val_accuracy: 0.9203\n",
            "Epoch 548/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.2613e-04 - accuracy: 1.0000 - val_loss: 0.7619 - val_accuracy: 0.9203\n",
            "Epoch 549/1000\n",
            "67/67 [==============================] - 0s 5ms/step - loss: 3.0452e-04 - accuracy: 1.0000 - val_loss: 0.7649 - val_accuracy: 0.9203\n",
            "Epoch 550/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.9055e-04 - accuracy: 1.0000 - val_loss: 0.7681 - val_accuracy: 0.9203\n",
            "Epoch 551/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.8265e-04 - accuracy: 1.0000 - val_loss: 0.7700 - val_accuracy: 0.9203\n",
            "Epoch 552/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.6828e-04 - accuracy: 1.0000 - val_loss: 0.7724 - val_accuracy: 0.9203\n",
            "Epoch 553/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.5478e-04 - accuracy: 1.0000 - val_loss: 0.7742 - val_accuracy: 0.9184\n",
            "Epoch 554/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.4286e-04 - accuracy: 1.0000 - val_loss: 0.7763 - val_accuracy: 0.9184\n",
            "Epoch 555/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.3420e-04 - accuracy: 1.0000 - val_loss: 0.7789 - val_accuracy: 0.9165\n",
            "Epoch 556/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.2273e-04 - accuracy: 1.0000 - val_loss: 0.7810 - val_accuracy: 0.9165\n",
            "Epoch 557/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.1808e-04 - accuracy: 1.0000 - val_loss: 0.7845 - val_accuracy: 0.9146\n",
            "Epoch 558/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.0732e-04 - accuracy: 1.0000 - val_loss: 0.7857 - val_accuracy: 0.9165\n",
            "Epoch 559/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.9817e-04 - accuracy: 1.0000 - val_loss: 0.7887 - val_accuracy: 0.9165\n",
            "Epoch 560/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.9064e-04 - accuracy: 1.0000 - val_loss: 0.7902 - val_accuracy: 0.9165\n",
            "Epoch 561/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.8685e-04 - accuracy: 1.0000 - val_loss: 0.7942 - val_accuracy: 0.9165\n",
            "Epoch 562/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.7929e-04 - accuracy: 1.0000 - val_loss: 0.7959 - val_accuracy: 0.9165\n",
            "Epoch 563/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.7216e-04 - accuracy: 1.0000 - val_loss: 0.7998 - val_accuracy: 0.9165\n",
            "Epoch 564/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.6799e-04 - accuracy: 1.0000 - val_loss: 0.8016 - val_accuracy: 0.9165\n",
            "Epoch 565/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.6100e-04 - accuracy: 1.0000 - val_loss: 0.8045 - val_accuracy: 0.9165\n",
            "Epoch 566/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.5475e-04 - accuracy: 1.0000 - val_loss: 0.8048 - val_accuracy: 0.9165\n",
            "Epoch 567/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.4860e-04 - accuracy: 1.0000 - val_loss: 0.8072 - val_accuracy: 0.9165\n",
            "Epoch 568/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.4250e-04 - accuracy: 1.0000 - val_loss: 0.8115 - val_accuracy: 0.9165\n",
            "Epoch 569/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.3820e-04 - accuracy: 1.0000 - val_loss: 0.8131 - val_accuracy: 0.9165\n",
            "Epoch 570/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.3451e-04 - accuracy: 1.0000 - val_loss: 0.8165 - val_accuracy: 0.9165\n",
            "Epoch 571/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.2781e-04 - accuracy: 1.0000 - val_loss: 0.8186 - val_accuracy: 0.9165\n",
            "Epoch 572/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.2433e-04 - accuracy: 1.0000 - val_loss: 0.8217 - val_accuracy: 0.9165\n",
            "Epoch 573/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.2166e-04 - accuracy: 1.0000 - val_loss: 0.8254 - val_accuracy: 0.9146\n",
            "Epoch 574/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.1872e-04 - accuracy: 1.0000 - val_loss: 0.8242 - val_accuracy: 0.9165\n",
            "Epoch 575/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.1341e-04 - accuracy: 1.0000 - val_loss: 0.8302 - val_accuracy: 0.9146\n",
            "Epoch 576/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.1194e-04 - accuracy: 1.0000 - val_loss: 0.8320 - val_accuracy: 0.9165\n",
            "Epoch 577/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.0851e-04 - accuracy: 1.0000 - val_loss: 0.8324 - val_accuracy: 0.9165\n",
            "Epoch 578/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.0387e-04 - accuracy: 1.0000 - val_loss: 0.8346 - val_accuracy: 0.9165\n",
            "Epoch 579/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.0301e-04 - accuracy: 1.0000 - val_loss: 0.8363 - val_accuracy: 0.9165\n",
            "Epoch 580/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 9.9607e-05 - accuracy: 1.0000 - val_loss: 0.8405 - val_accuracy: 0.9165\n",
            "Epoch 581/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 9.7234e-05 - accuracy: 1.0000 - val_loss: 0.8452 - val_accuracy: 0.9165\n",
            "Epoch 582/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 9.5130e-05 - accuracy: 1.0000 - val_loss: 0.8450 - val_accuracy: 0.9165\n",
            "Epoch 583/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 9.0813e-05 - accuracy: 1.0000 - val_loss: 0.8473 - val_accuracy: 0.9165\n",
            "Epoch 584/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 8.8391e-05 - accuracy: 1.0000 - val_loss: 0.8522 - val_accuracy: 0.9146\n",
            "Epoch 585/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 8.8249e-05 - accuracy: 1.0000 - val_loss: 0.8525 - val_accuracy: 0.9165\n",
            "Epoch 586/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 8.3216e-05 - accuracy: 1.0000 - val_loss: 0.8549 - val_accuracy: 0.9165\n",
            "Epoch 587/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 8.0275e-05 - accuracy: 1.0000 - val_loss: 0.8577 - val_accuracy: 0.9165\n",
            "Epoch 588/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 8.0439e-05 - accuracy: 1.0000 - val_loss: 0.8595 - val_accuracy: 0.9165\n",
            "Epoch 589/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.9096e-05 - accuracy: 1.0000 - val_loss: 0.8634 - val_accuracy: 0.9165\n",
            "Epoch 590/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.8971e-05 - accuracy: 1.0000 - val_loss: 0.8639 - val_accuracy: 0.9165\n",
            "Epoch 591/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 7.7154e-05 - accuracy: 1.0000 - val_loss: 0.8704 - val_accuracy: 0.9165\n",
            "Epoch 592/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 7.3334e-05 - accuracy: 1.0000 - val_loss: 0.8673 - val_accuracy: 0.9165\n",
            "Epoch 593/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.0960e-05 - accuracy: 1.0000 - val_loss: 0.8712 - val_accuracy: 0.9165\n",
            "Epoch 594/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.9313e-05 - accuracy: 1.0000 - val_loss: 0.8754 - val_accuracy: 0.9165\n",
            "Epoch 595/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 6.7544e-05 - accuracy: 1.0000 - val_loss: 0.8776 - val_accuracy: 0.9165\n",
            "Epoch 596/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 6.6229e-05 - accuracy: 1.0000 - val_loss: 0.8746 - val_accuracy: 0.9165\n",
            "Epoch 597/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.3943e-05 - accuracy: 1.0000 - val_loss: 0.8827 - val_accuracy: 0.9165\n",
            "Epoch 598/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.7002e-05 - accuracy: 1.0000 - val_loss: 0.8811 - val_accuracy: 0.9165\n",
            "Epoch 599/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.6172e-05 - accuracy: 1.0000 - val_loss: 0.8835 - val_accuracy: 0.9165\n",
            "Epoch 600/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 6.0325e-05 - accuracy: 1.0000 - val_loss: 0.8856 - val_accuracy: 0.9165\n",
            "Epoch 601/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 6.0858e-05 - accuracy: 1.0000 - val_loss: 0.8907 - val_accuracy: 0.9165\n",
            "Epoch 602/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.9010e-05 - accuracy: 1.0000 - val_loss: 0.8844 - val_accuracy: 0.9165\n",
            "Epoch 603/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 8.3835e-05 - accuracy: 1.0000 - val_loss: 0.8920 - val_accuracy: 0.9165\n",
            "Epoch 604/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.8001e-05 - accuracy: 1.0000 - val_loss: 0.8967 - val_accuracy: 0.9165\n",
            "Epoch 605/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.3358e-05 - accuracy: 1.0000 - val_loss: 0.9031 - val_accuracy: 0.9165\n",
            "Epoch 606/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.1484e-05 - accuracy: 1.0000 - val_loss: 0.9000 - val_accuracy: 0.9165\n",
            "Epoch 607/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.9347e-05 - accuracy: 1.0000 - val_loss: 0.8874 - val_accuracy: 0.9165\n",
            "Epoch 608/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 8.0892e-05 - accuracy: 1.0000 - val_loss: 0.8870 - val_accuracy: 0.9184\n",
            "Epoch 609/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 1.0769 - val_accuracy: 0.9203\n",
            "Epoch 610/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.1208 - accuracy: 0.9859 - val_loss: 0.9364 - val_accuracy: 0.9203\n",
            "Epoch 611/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0279 - accuracy: 0.9916 - val_loss: 0.9250 - val_accuracy: 0.9146\n",
            "Epoch 612/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.8990 - val_accuracy: 0.9146\n",
            "Epoch 613/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.3958e-04 - accuracy: 1.0000 - val_loss: 0.8962 - val_accuracy: 0.9127\n",
            "Epoch 614/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.9868e-04 - accuracy: 1.0000 - val_loss: 0.8996 - val_accuracy: 0.9127\n",
            "Epoch 615/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.7241e-04 - accuracy: 1.0000 - val_loss: 0.9004 - val_accuracy: 0.9127\n",
            "Epoch 616/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.4924e-04 - accuracy: 1.0000 - val_loss: 0.9017 - val_accuracy: 0.9146\n",
            "Epoch 617/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.3160e-04 - accuracy: 1.0000 - val_loss: 0.9028 - val_accuracy: 0.9146\n",
            "Epoch 618/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.1671e-04 - accuracy: 1.0000 - val_loss: 0.9050 - val_accuracy: 0.9146\n",
            "Epoch 619/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.0348e-04 - accuracy: 1.0000 - val_loss: 0.9054 - val_accuracy: 0.9146\n",
            "Epoch 620/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.9084e-04 - accuracy: 1.0000 - val_loss: 0.9070 - val_accuracy: 0.9146\n",
            "Epoch 621/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.8460e-04 - accuracy: 1.0000 - val_loss: 0.9072 - val_accuracy: 0.9146\n",
            "Epoch 622/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.7423e-04 - accuracy: 1.0000 - val_loss: 0.9102 - val_accuracy: 0.9146\n",
            "Epoch 623/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.6613e-04 - accuracy: 1.0000 - val_loss: 0.9109 - val_accuracy: 0.9146\n",
            "Epoch 624/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.6014e-04 - accuracy: 1.0000 - val_loss: 0.9120 - val_accuracy: 0.9146\n",
            "Epoch 625/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.5338e-04 - accuracy: 1.0000 - val_loss: 0.9135 - val_accuracy: 0.9146\n",
            "Epoch 626/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.4759e-04 - accuracy: 1.0000 - val_loss: 0.9152 - val_accuracy: 0.9146\n",
            "Epoch 627/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.4289e-04 - accuracy: 1.0000 - val_loss: 0.9158 - val_accuracy: 0.9146\n",
            "Epoch 628/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.3742e-04 - accuracy: 1.0000 - val_loss: 0.9175 - val_accuracy: 0.9146\n",
            "Epoch 629/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.3189e-04 - accuracy: 1.0000 - val_loss: 0.9192 - val_accuracy: 0.9165\n",
            "Epoch 630/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.2932e-04 - accuracy: 1.0000 - val_loss: 0.9207 - val_accuracy: 0.9165\n",
            "Epoch 631/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.2420e-04 - accuracy: 1.0000 - val_loss: 0.9208 - val_accuracy: 0.9165\n",
            "Epoch 632/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.1951e-04 - accuracy: 1.0000 - val_loss: 0.9224 - val_accuracy: 0.9165\n",
            "Epoch 633/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.1670e-04 - accuracy: 1.0000 - val_loss: 0.9243 - val_accuracy: 0.9165\n",
            "Epoch 634/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.1313e-04 - accuracy: 1.0000 - val_loss: 0.9253 - val_accuracy: 0.9165\n",
            "Epoch 635/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.0975e-04 - accuracy: 1.0000 - val_loss: 0.9270 - val_accuracy: 0.9165\n",
            "Epoch 636/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.0702e-04 - accuracy: 1.0000 - val_loss: 0.9282 - val_accuracy: 0.9165\n",
            "Epoch 637/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.0477e-04 - accuracy: 1.0000 - val_loss: 0.9303 - val_accuracy: 0.9165\n",
            "Epoch 638/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.0216e-04 - accuracy: 1.0000 - val_loss: 0.9325 - val_accuracy: 0.9165\n",
            "Epoch 639/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 9.8907e-05 - accuracy: 1.0000 - val_loss: 0.9326 - val_accuracy: 0.9165\n",
            "Epoch 640/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 9.6488e-05 - accuracy: 1.0000 - val_loss: 0.9349 - val_accuracy: 0.9165\n",
            "Epoch 641/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 9.3680e-05 - accuracy: 1.0000 - val_loss: 0.9368 - val_accuracy: 0.9165\n",
            "Epoch 642/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 9.1861e-05 - accuracy: 1.0000 - val_loss: 0.9389 - val_accuracy: 0.9165\n",
            "Epoch 643/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 8.9638e-05 - accuracy: 1.0000 - val_loss: 0.9387 - val_accuracy: 0.9165\n",
            "Epoch 644/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 8.8631e-05 - accuracy: 1.0000 - val_loss: 0.9423 - val_accuracy: 0.9165\n",
            "Epoch 645/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 8.4519e-05 - accuracy: 1.0000 - val_loss: 0.9418 - val_accuracy: 0.9165\n",
            "Epoch 646/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 8.3927e-05 - accuracy: 1.0000 - val_loss: 0.9447 - val_accuracy: 0.9165\n",
            "Epoch 647/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 8.1186e-05 - accuracy: 1.0000 - val_loss: 0.9462 - val_accuracy: 0.9165\n",
            "Epoch 648/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 8.0160e-05 - accuracy: 1.0000 - val_loss: 0.9490 - val_accuracy: 0.9165\n",
            "Epoch 649/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 7.7683e-05 - accuracy: 1.0000 - val_loss: 0.9508 - val_accuracy: 0.9165\n",
            "Epoch 650/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 7.6850e-05 - accuracy: 1.0000 - val_loss: 0.9488 - val_accuracy: 0.9165\n",
            "Epoch 651/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.6544e-05 - accuracy: 1.0000 - val_loss: 0.9524 - val_accuracy: 0.9165\n",
            "Epoch 652/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.3403e-05 - accuracy: 1.0000 - val_loss: 0.9572 - val_accuracy: 0.9165\n",
            "Epoch 653/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 7.0559e-05 - accuracy: 1.0000 - val_loss: 0.9560 - val_accuracy: 0.9165\n",
            "Epoch 654/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.9758e-05 - accuracy: 1.0000 - val_loss: 0.9572 - val_accuracy: 0.9165\n",
            "Epoch 655/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.8299e-05 - accuracy: 1.0000 - val_loss: 0.9603 - val_accuracy: 0.9165\n",
            "Epoch 656/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 6.7991e-05 - accuracy: 1.0000 - val_loss: 0.9596 - val_accuracy: 0.9165\n",
            "Epoch 657/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.4541e-05 - accuracy: 1.0000 - val_loss: 0.9640 - val_accuracy: 0.9165\n",
            "Epoch 658/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.3009e-05 - accuracy: 1.0000 - val_loss: 0.9669 - val_accuracy: 0.9165\n",
            "Epoch 659/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.5276e-05 - accuracy: 1.0000 - val_loss: 0.9684 - val_accuracy: 0.9165\n",
            "Epoch 660/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 6.2114e-05 - accuracy: 1.0000 - val_loss: 0.9682 - val_accuracy: 0.9165\n",
            "Epoch 661/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.0903e-05 - accuracy: 1.0000 - val_loss: 0.9702 - val_accuracy: 0.9165\n",
            "Epoch 662/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.3814e-05 - accuracy: 1.0000 - val_loss: 0.9769 - val_accuracy: 0.9165\n",
            "Epoch 663/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 8.1474e-05 - accuracy: 1.0000 - val_loss: 0.9781 - val_accuracy: 0.9165\n",
            "Epoch 664/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 7.1069e-05 - accuracy: 1.0000 - val_loss: 0.9775 - val_accuracy: 0.9165\n",
            "Epoch 665/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 6.2741e-05 - accuracy: 1.0000 - val_loss: 0.9740 - val_accuracy: 0.9165\n",
            "Epoch 666/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.6171e-05 - accuracy: 1.0000 - val_loss: 0.9749 - val_accuracy: 0.9165\n",
            "Epoch 667/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.3502e-05 - accuracy: 1.0000 - val_loss: 0.9776 - val_accuracy: 0.9165\n",
            "Epoch 668/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.2209e-05 - accuracy: 1.0000 - val_loss: 0.9803 - val_accuracy: 0.9165\n",
            "Epoch 669/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.4094e-05 - accuracy: 1.0000 - val_loss: 0.9781 - val_accuracy: 0.9165\n",
            "Epoch 670/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 7.4548e-05 - accuracy: 1.0000 - val_loss: 0.9781 - val_accuracy: 0.9165\n",
            "Epoch 671/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 6.0534e-05 - accuracy: 1.0000 - val_loss: 0.9918 - val_accuracy: 0.9165\n",
            "Epoch 672/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.0736e-05 - accuracy: 1.0000 - val_loss: 0.9889 - val_accuracy: 0.9165\n",
            "Epoch 673/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.6767e-05 - accuracy: 1.0000 - val_loss: 0.9893 - val_accuracy: 0.9165\n",
            "Epoch 674/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.4199e-05 - accuracy: 1.0000 - val_loss: 0.9924 - val_accuracy: 0.9165\n",
            "Epoch 675/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.3362e-05 - accuracy: 1.0000 - val_loss: 0.9981 - val_accuracy: 0.9165\n",
            "Epoch 676/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.6782e-05 - accuracy: 1.0000 - val_loss: 0.9905 - val_accuracy: 0.9165\n",
            "Epoch 677/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.3630e-05 - accuracy: 1.0000 - val_loss: 0.9844 - val_accuracy: 0.9165\n",
            "Epoch 678/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.3225e-05 - accuracy: 1.0000 - val_loss: 1.0032 - val_accuracy: 0.9165\n",
            "Epoch 679/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.0548e-05 - accuracy: 1.0000 - val_loss: 1.0024 - val_accuracy: 0.9165\n",
            "Epoch 680/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.9752e-05 - accuracy: 1.0000 - val_loss: 1.0012 - val_accuracy: 0.9165\n",
            "Epoch 681/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.0995e-05 - accuracy: 1.0000 - val_loss: 1.0036 - val_accuracy: 0.9165\n",
            "Epoch 682/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.1335e-05 - accuracy: 1.0000 - val_loss: 1.0074 - val_accuracy: 0.9165\n",
            "Epoch 683/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.2909e-05 - accuracy: 1.0000 - val_loss: 1.0167 - val_accuracy: 0.9165\n",
            "Epoch 684/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.0808e-05 - accuracy: 1.0000 - val_loss: 1.0058 - val_accuracy: 0.9165\n",
            "Epoch 685/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.5740e-05 - accuracy: 1.0000 - val_loss: 1.0184 - val_accuracy: 0.9165\n",
            "Epoch 686/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.7579e-05 - accuracy: 1.0000 - val_loss: 1.0121 - val_accuracy: 0.9165\n",
            "Epoch 687/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.8130e-05 - accuracy: 1.0000 - val_loss: 1.0179 - val_accuracy: 0.9165\n",
            "Epoch 688/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.3824e-05 - accuracy: 1.0000 - val_loss: 1.0238 - val_accuracy: 0.9165\n",
            "Epoch 689/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.3126e-05 - accuracy: 1.0000 - val_loss: 1.0151 - val_accuracy: 0.9146\n",
            "Epoch 690/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.2412e-05 - accuracy: 1.0000 - val_loss: 1.0242 - val_accuracy: 0.9146\n",
            "Epoch 691/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.4984e-05 - accuracy: 1.0000 - val_loss: 1.0266 - val_accuracy: 0.9146\n",
            "Epoch 692/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.2218e-05 - accuracy: 1.0000 - val_loss: 1.0083 - val_accuracy: 0.9184\n",
            "Epoch 693/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9991 - val_loss: 0.9637 - val_accuracy: 0.9146\n",
            "Epoch 694/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.9563 - val_accuracy: 0.9127\n",
            "Epoch 695/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 7.2235e-04 - accuracy: 1.0000 - val_loss: 0.9799 - val_accuracy: 0.9146\n",
            "Epoch 696/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 0.9925 - val_loss: 0.8792 - val_accuracy: 0.9184\n",
            "Epoch 697/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.0397 - accuracy: 0.9934 - val_loss: 1.0696 - val_accuracy: 0.9127\n",
            "Epoch 698/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9906 - val_loss: 0.9282 - val_accuracy: 0.9165\n",
            "Epoch 699/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.0426 - accuracy: 0.9878 - val_loss: 0.9136 - val_accuracy: 0.9127\n",
            "Epoch 700/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9981 - val_loss: 0.9472 - val_accuracy: 0.9127\n",
            "Epoch 701/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.9258 - val_accuracy: 0.9146\n",
            "Epoch 702/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 8.0927e-04 - accuracy: 1.0000 - val_loss: 0.9128 - val_accuracy: 0.9146\n",
            "Epoch 703/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.4029e-04 - accuracy: 1.0000 - val_loss: 0.9226 - val_accuracy: 0.9089\n",
            "Epoch 704/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.7916e-04 - accuracy: 1.0000 - val_loss: 0.9198 - val_accuracy: 0.9089\n",
            "Epoch 705/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.3289e-04 - accuracy: 1.0000 - val_loss: 0.9214 - val_accuracy: 0.9089\n",
            "Epoch 706/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.0296e-04 - accuracy: 1.0000 - val_loss: 0.9208 - val_accuracy: 0.9089\n",
            "Epoch 707/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.6855e-04 - accuracy: 1.0000 - val_loss: 0.9209 - val_accuracy: 0.9108\n",
            "Epoch 708/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.4959e-04 - accuracy: 1.0000 - val_loss: 0.9238 - val_accuracy: 0.9108\n",
            "Epoch 709/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 3.3471e-04 - accuracy: 1.0000 - val_loss: 0.9244 - val_accuracy: 0.9108\n",
            "Epoch 710/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.0621e-04 - accuracy: 1.0000 - val_loss: 0.9246 - val_accuracy: 0.9108\n",
            "Epoch 711/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.8608e-04 - accuracy: 1.0000 - val_loss: 0.9254 - val_accuracy: 0.9108\n",
            "Epoch 712/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.7015e-04 - accuracy: 1.0000 - val_loss: 0.9270 - val_accuracy: 0.9108\n",
            "Epoch 713/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.5905e-04 - accuracy: 1.0000 - val_loss: 0.9275 - val_accuracy: 0.9108\n",
            "Epoch 714/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.4613e-04 - accuracy: 1.0000 - val_loss: 0.9292 - val_accuracy: 0.9108\n",
            "Epoch 715/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.3543e-04 - accuracy: 1.0000 - val_loss: 0.9310 - val_accuracy: 0.9108\n",
            "Epoch 716/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.2788e-04 - accuracy: 1.0000 - val_loss: 0.9327 - val_accuracy: 0.9127\n",
            "Epoch 717/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.1675e-04 - accuracy: 1.0000 - val_loss: 0.9342 - val_accuracy: 0.9108\n",
            "Epoch 718/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.0565e-04 - accuracy: 1.0000 - val_loss: 0.9359 - val_accuracy: 0.9108\n",
            "Epoch 719/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.9676e-04 - accuracy: 1.0000 - val_loss: 0.9388 - val_accuracy: 0.9127\n",
            "Epoch 720/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.8817e-04 - accuracy: 1.0000 - val_loss: 0.9377 - val_accuracy: 0.9108\n",
            "Epoch 721/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.7908e-04 - accuracy: 1.0000 - val_loss: 0.9396 - val_accuracy: 0.9108\n",
            "Epoch 722/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.7486e-04 - accuracy: 1.0000 - val_loss: 0.9399 - val_accuracy: 0.9108\n",
            "Epoch 723/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.6719e-04 - accuracy: 1.0000 - val_loss: 0.9408 - val_accuracy: 0.9108\n",
            "Epoch 724/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.6068e-04 - accuracy: 1.0000 - val_loss: 0.9437 - val_accuracy: 0.9089\n",
            "Epoch 725/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.5504e-04 - accuracy: 1.0000 - val_loss: 0.9441 - val_accuracy: 0.9089\n",
            "Epoch 726/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.5132e-04 - accuracy: 1.0000 - val_loss: 0.9459 - val_accuracy: 0.9089\n",
            "Epoch 727/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.4383e-04 - accuracy: 1.0000 - val_loss: 0.9476 - val_accuracy: 0.9089\n",
            "Epoch 728/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.3888e-04 - accuracy: 1.0000 - val_loss: 0.9487 - val_accuracy: 0.9089\n",
            "Epoch 729/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.3393e-04 - accuracy: 1.0000 - val_loss: 0.9494 - val_accuracy: 0.9089\n",
            "Epoch 730/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.3008e-04 - accuracy: 1.0000 - val_loss: 0.9521 - val_accuracy: 0.9089\n",
            "Epoch 731/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.2585e-04 - accuracy: 1.0000 - val_loss: 0.9524 - val_accuracy: 0.9089\n",
            "Epoch 732/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.2227e-04 - accuracy: 1.0000 - val_loss: 0.9546 - val_accuracy: 0.9089\n",
            "Epoch 733/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.1750e-04 - accuracy: 1.0000 - val_loss: 0.9560 - val_accuracy: 0.9089\n",
            "Epoch 734/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.1327e-04 - accuracy: 1.0000 - val_loss: 0.9563 - val_accuracy: 0.9089\n",
            "Epoch 735/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.1088e-04 - accuracy: 1.0000 - val_loss: 0.9573 - val_accuracy: 0.9089\n",
            "Epoch 736/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.0697e-04 - accuracy: 1.0000 - val_loss: 0.9598 - val_accuracy: 0.9089\n",
            "Epoch 737/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.0346e-04 - accuracy: 1.0000 - val_loss: 0.9614 - val_accuracy: 0.9089\n",
            "Epoch 738/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 9.9846e-05 - accuracy: 1.0000 - val_loss: 0.9629 - val_accuracy: 0.9089\n",
            "Epoch 739/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 9.6385e-05 - accuracy: 1.0000 - val_loss: 0.9640 - val_accuracy: 0.9089\n",
            "Epoch 740/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 9.2993e-05 - accuracy: 1.0000 - val_loss: 0.9655 - val_accuracy: 0.9089\n",
            "Epoch 741/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 9.0206e-05 - accuracy: 1.0000 - val_loss: 0.9661 - val_accuracy: 0.9108\n",
            "Epoch 742/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 8.8240e-05 - accuracy: 1.0000 - val_loss: 0.9688 - val_accuracy: 0.9108\n",
            "Epoch 743/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 8.5766e-05 - accuracy: 1.0000 - val_loss: 0.9708 - val_accuracy: 0.9108\n",
            "Epoch 744/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 8.3095e-05 - accuracy: 1.0000 - val_loss: 0.9716 - val_accuracy: 0.9108\n",
            "Epoch 745/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 7.9501e-05 - accuracy: 1.0000 - val_loss: 0.9735 - val_accuracy: 0.9108\n",
            "Epoch 746/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.7771e-05 - accuracy: 1.0000 - val_loss: 0.9765 - val_accuracy: 0.9108\n",
            "Epoch 747/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 7.5347e-05 - accuracy: 1.0000 - val_loss: 0.9772 - val_accuracy: 0.9108\n",
            "Epoch 748/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.3919e-05 - accuracy: 1.0000 - val_loss: 0.9807 - val_accuracy: 0.9089\n",
            "Epoch 749/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 7.1926e-05 - accuracy: 1.0000 - val_loss: 0.9819 - val_accuracy: 0.9108\n",
            "Epoch 750/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 6.9167e-05 - accuracy: 1.0000 - val_loss: 0.9820 - val_accuracy: 0.9108\n",
            "Epoch 751/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.7358e-05 - accuracy: 1.0000 - val_loss: 0.9848 - val_accuracy: 0.9108\n",
            "Epoch 752/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 6.5729e-05 - accuracy: 1.0000 - val_loss: 0.9867 - val_accuracy: 0.9108\n",
            "Epoch 753/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 6.4559e-05 - accuracy: 1.0000 - val_loss: 0.9888 - val_accuracy: 0.9108\n",
            "Epoch 754/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 6.2630e-05 - accuracy: 1.0000 - val_loss: 0.9882 - val_accuracy: 0.9108\n",
            "Epoch 755/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.9938e-05 - accuracy: 1.0000 - val_loss: 0.9928 - val_accuracy: 0.9108\n",
            "Epoch 756/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 6.0026e-05 - accuracy: 1.0000 - val_loss: 0.9925 - val_accuracy: 0.9108\n",
            "Epoch 757/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 5.7249e-05 - accuracy: 1.0000 - val_loss: 0.9931 - val_accuracy: 0.9108\n",
            "Epoch 758/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.6576e-05 - accuracy: 1.0000 - val_loss: 0.9951 - val_accuracy: 0.9108\n",
            "Epoch 759/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.4065e-05 - accuracy: 1.0000 - val_loss: 0.9966 - val_accuracy: 0.9108\n",
            "Epoch 760/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.2750e-05 - accuracy: 1.0000 - val_loss: 0.9985 - val_accuracy: 0.9108\n",
            "Epoch 761/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.1549e-05 - accuracy: 1.0000 - val_loss: 1.0004 - val_accuracy: 0.9108\n",
            "Epoch 762/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.0446e-05 - accuracy: 1.0000 - val_loss: 1.0004 - val_accuracy: 0.9108\n",
            "Epoch 763/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.9589e-05 - accuracy: 1.0000 - val_loss: 1.0035 - val_accuracy: 0.9108\n",
            "Epoch 764/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.8296e-05 - accuracy: 1.0000 - val_loss: 1.0046 - val_accuracy: 0.9108\n",
            "Epoch 765/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.5985e-05 - accuracy: 1.0000 - val_loss: 1.0085 - val_accuracy: 0.9108\n",
            "Epoch 766/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.6332e-05 - accuracy: 1.0000 - val_loss: 1.0100 - val_accuracy: 0.9108\n",
            "Epoch 767/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.3652e-05 - accuracy: 1.0000 - val_loss: 1.0078 - val_accuracy: 0.9108\n",
            "Epoch 768/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.3196e-05 - accuracy: 1.0000 - val_loss: 1.0116 - val_accuracy: 0.9108\n",
            "Epoch 769/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.2520e-05 - accuracy: 1.0000 - val_loss: 1.0132 - val_accuracy: 0.9108\n",
            "Epoch 770/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.0789e-05 - accuracy: 1.0000 - val_loss: 1.0129 - val_accuracy: 0.9108\n",
            "Epoch 771/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.0330e-05 - accuracy: 1.0000 - val_loss: 1.0128 - val_accuracy: 0.9108\n",
            "Epoch 772/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.8825e-05 - accuracy: 1.0000 - val_loss: 1.0170 - val_accuracy: 0.9108\n",
            "Epoch 773/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.7781e-05 - accuracy: 1.0000 - val_loss: 1.0171 - val_accuracy: 0.9108\n",
            "Epoch 774/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.6996e-05 - accuracy: 1.0000 - val_loss: 1.0204 - val_accuracy: 0.9108\n",
            "Epoch 775/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.6048e-05 - accuracy: 1.0000 - val_loss: 1.0223 - val_accuracy: 0.9108\n",
            "Epoch 776/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.5323e-05 - accuracy: 1.0000 - val_loss: 1.0267 - val_accuracy: 0.9108\n",
            "Epoch 777/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.4881e-05 - accuracy: 1.0000 - val_loss: 1.0206 - val_accuracy: 0.9108\n",
            "Epoch 778/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.3772e-05 - accuracy: 1.0000 - val_loss: 1.0299 - val_accuracy: 0.9108\n",
            "Epoch 779/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.3649e-05 - accuracy: 1.0000 - val_loss: 1.0310 - val_accuracy: 0.9108\n",
            "Epoch 780/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.1773e-05 - accuracy: 1.0000 - val_loss: 1.0293 - val_accuracy: 0.9108\n",
            "Epoch 781/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.1297e-05 - accuracy: 1.0000 - val_loss: 1.0305 - val_accuracy: 0.9108\n",
            "Epoch 782/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.1057e-05 - accuracy: 1.0000 - val_loss: 1.0331 - val_accuracy: 0.9108\n",
            "Epoch 783/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.9202e-05 - accuracy: 1.0000 - val_loss: 1.0386 - val_accuracy: 0.9108\n",
            "Epoch 784/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.9411e-05 - accuracy: 1.0000 - val_loss: 1.0339 - val_accuracy: 0.9108\n",
            "Epoch 785/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.2055e-05 - accuracy: 1.0000 - val_loss: 1.0447 - val_accuracy: 0.9108\n",
            "Epoch 786/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.8013e-05 - accuracy: 1.0000 - val_loss: 1.0399 - val_accuracy: 0.9108\n",
            "Epoch 787/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.8468e-05 - accuracy: 1.0000 - val_loss: 1.0423 - val_accuracy: 0.9108\n",
            "Epoch 788/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.5779e-05 - accuracy: 1.0000 - val_loss: 1.0462 - val_accuracy: 0.9108\n",
            "Epoch 789/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.5247e-05 - accuracy: 1.0000 - val_loss: 1.0436 - val_accuracy: 0.9108\n",
            "Epoch 790/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.5247e-05 - accuracy: 1.0000 - val_loss: 1.0565 - val_accuracy: 0.9089\n",
            "Epoch 791/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.6037e-05 - accuracy: 1.0000 - val_loss: 1.0498 - val_accuracy: 0.9108\n",
            "Epoch 792/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.4672e-05 - accuracy: 1.0000 - val_loss: 1.0528 - val_accuracy: 0.9108\n",
            "Epoch 793/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.2882e-05 - accuracy: 1.0000 - val_loss: 1.0565 - val_accuracy: 0.9108\n",
            "Epoch 794/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.2235e-05 - accuracy: 1.0000 - val_loss: 1.0560 - val_accuracy: 0.9108\n",
            "Epoch 795/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.3436e-05 - accuracy: 1.0000 - val_loss: 1.0594 - val_accuracy: 0.9108\n",
            "Epoch 796/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.1804e-05 - accuracy: 1.0000 - val_loss: 1.0573 - val_accuracy: 0.9108\n",
            "Epoch 797/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.1129e-05 - accuracy: 1.0000 - val_loss: 1.0678 - val_accuracy: 0.9108\n",
            "Epoch 798/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.5014e-05 - accuracy: 1.0000 - val_loss: 1.0726 - val_accuracy: 0.9089\n",
            "Epoch 799/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.1212e-05 - accuracy: 1.0000 - val_loss: 1.0591 - val_accuracy: 0.9108\n",
            "Epoch 800/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.3295e-05 - accuracy: 1.0000 - val_loss: 1.0737 - val_accuracy: 0.9108\n",
            "Epoch 801/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.0060e-05 - accuracy: 1.0000 - val_loss: 1.0757 - val_accuracy: 0.9108\n",
            "Epoch 802/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.9538e-05 - accuracy: 1.0000 - val_loss: 1.0860 - val_accuracy: 0.9089\n",
            "Epoch 803/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.9597e-05 - accuracy: 1.0000 - val_loss: 1.0709 - val_accuracy: 0.9108\n",
            "Epoch 804/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.8254e-05 - accuracy: 1.0000 - val_loss: 1.0828 - val_accuracy: 0.9108\n",
            "Epoch 805/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.8289e-05 - accuracy: 1.0000 - val_loss: 1.0793 - val_accuracy: 0.9108\n",
            "Epoch 806/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.1718e-05 - accuracy: 1.0000 - val_loss: 1.0944 - val_accuracy: 0.9089\n",
            "Epoch 807/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.1777e-05 - accuracy: 1.0000 - val_loss: 1.0939 - val_accuracy: 0.9089\n",
            "Epoch 808/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.0177e-05 - accuracy: 1.0000 - val_loss: 1.0874 - val_accuracy: 0.9108\n",
            "Epoch 809/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.7808e-05 - accuracy: 1.0000 - val_loss: 1.1009 - val_accuracy: 0.9108\n",
            "Epoch 810/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.4104e-05 - accuracy: 1.0000 - val_loss: 1.0937 - val_accuracy: 0.9108\n",
            "Epoch 811/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.5041e-05 - accuracy: 1.0000 - val_loss: 1.1160 - val_accuracy: 0.9070\n",
            "Epoch 812/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 1.2135 - val_accuracy: 0.9241\n",
            "Epoch 813/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9888 - val_loss: 1.1397 - val_accuracy: 0.9241\n",
            "Epoch 814/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.9888 - val_loss: 1.0897 - val_accuracy: 0.9222\n",
            "Epoch 815/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.9916 - val_loss: 0.9913 - val_accuracy: 0.9184\n",
            "Epoch 816/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.9407 - val_accuracy: 0.9184\n",
            "Epoch 817/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9140 - val_accuracy: 0.9241\n",
            "Epoch 818/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.2660e-04 - accuracy: 1.0000 - val_loss: 0.9159 - val_accuracy: 0.9241\n",
            "Epoch 819/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.9872e-04 - accuracy: 1.0000 - val_loss: 0.9171 - val_accuracy: 0.9260\n",
            "Epoch 820/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.8316e-04 - accuracy: 1.0000 - val_loss: 0.9183 - val_accuracy: 0.9260\n",
            "Epoch 821/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.6990e-04 - accuracy: 1.0000 - val_loss: 0.9206 - val_accuracy: 0.9260\n",
            "Epoch 822/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.5748e-04 - accuracy: 1.0000 - val_loss: 0.9206 - val_accuracy: 0.9260\n",
            "Epoch 823/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.4928e-04 - accuracy: 1.0000 - val_loss: 0.9221 - val_accuracy: 0.9260\n",
            "Epoch 824/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.4206e-04 - accuracy: 1.0000 - val_loss: 0.9233 - val_accuracy: 0.9260\n",
            "Epoch 825/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.3503e-04 - accuracy: 1.0000 - val_loss: 0.9246 - val_accuracy: 0.9241\n",
            "Epoch 826/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.2997e-04 - accuracy: 1.0000 - val_loss: 0.9259 - val_accuracy: 0.9241\n",
            "Epoch 827/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.2711e-04 - accuracy: 1.0000 - val_loss: 0.9266 - val_accuracy: 0.9241\n",
            "Epoch 828/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.2018e-04 - accuracy: 1.0000 - val_loss: 0.9281 - val_accuracy: 0.9241\n",
            "Epoch 829/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.1716e-04 - accuracy: 1.0000 - val_loss: 0.9295 - val_accuracy: 0.9241\n",
            "Epoch 830/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.1230e-04 - accuracy: 1.0000 - val_loss: 0.9305 - val_accuracy: 0.9241\n",
            "Epoch 831/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.0768e-04 - accuracy: 1.0000 - val_loss: 0.9316 - val_accuracy: 0.9241\n",
            "Epoch 832/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.0213e-04 - accuracy: 1.0000 - val_loss: 0.9325 - val_accuracy: 0.9241\n",
            "Epoch 833/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 9.9236e-05 - accuracy: 1.0000 - val_loss: 0.9333 - val_accuracy: 0.9241\n",
            "Epoch 834/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 9.6847e-05 - accuracy: 1.0000 - val_loss: 0.9344 - val_accuracy: 0.9241\n",
            "Epoch 835/1000\n",
            "67/67 [==============================] - 0s 5ms/step - loss: 9.3264e-05 - accuracy: 1.0000 - val_loss: 0.9355 - val_accuracy: 0.9241\n",
            "Epoch 836/1000\n",
            "67/67 [==============================] - 0s 5ms/step - loss: 8.9827e-05 - accuracy: 1.0000 - val_loss: 0.9368 - val_accuracy: 0.9222\n",
            "Epoch 837/1000\n",
            "67/67 [==============================] - 0s 6ms/step - loss: 8.7479e-05 - accuracy: 1.0000 - val_loss: 0.9379 - val_accuracy: 0.9222\n",
            "Epoch 838/1000\n",
            "67/67 [==============================] - 0s 5ms/step - loss: 8.4613e-05 - accuracy: 1.0000 - val_loss: 0.9387 - val_accuracy: 0.9222\n",
            "Epoch 839/1000\n",
            "67/67 [==============================] - 0s 5ms/step - loss: 8.2247e-05 - accuracy: 1.0000 - val_loss: 0.9400 - val_accuracy: 0.9222\n",
            "Epoch 840/1000\n",
            "67/67 [==============================] - 0s 5ms/step - loss: 8.0360e-05 - accuracy: 1.0000 - val_loss: 0.9410 - val_accuracy: 0.9222\n",
            "Epoch 841/1000\n",
            "67/67 [==============================] - 0s 5ms/step - loss: 7.7661e-05 - accuracy: 1.0000 - val_loss: 0.9421 - val_accuracy: 0.9222\n",
            "Epoch 842/1000\n",
            "67/67 [==============================] - 0s 5ms/step - loss: 7.5128e-05 - accuracy: 1.0000 - val_loss: 0.9436 - val_accuracy: 0.9222\n",
            "Epoch 843/1000\n",
            "67/67 [==============================] - 0s 5ms/step - loss: 7.3275e-05 - accuracy: 1.0000 - val_loss: 0.9439 - val_accuracy: 0.9222\n",
            "Epoch 844/1000\n",
            "67/67 [==============================] - 0s 6ms/step - loss: 7.1007e-05 - accuracy: 1.0000 - val_loss: 0.9458 - val_accuracy: 0.9222\n",
            "Epoch 845/1000\n",
            "67/67 [==============================] - 0s 6ms/step - loss: 6.9359e-05 - accuracy: 1.0000 - val_loss: 0.9466 - val_accuracy: 0.9222\n",
            "Epoch 846/1000\n",
            "67/67 [==============================] - 0s 6ms/step - loss: 6.6821e-05 - accuracy: 1.0000 - val_loss: 0.9484 - val_accuracy: 0.9222\n",
            "Epoch 847/1000\n",
            "67/67 [==============================] - 0s 5ms/step - loss: 6.4907e-05 - accuracy: 1.0000 - val_loss: 0.9494 - val_accuracy: 0.9222\n",
            "Epoch 848/1000\n",
            "67/67 [==============================] - 0s 6ms/step - loss: 6.2099e-05 - accuracy: 1.0000 - val_loss: 0.9507 - val_accuracy: 0.9222\n",
            "Epoch 849/1000\n",
            "67/67 [==============================] - 0s 5ms/step - loss: 6.0604e-05 - accuracy: 1.0000 - val_loss: 0.9517 - val_accuracy: 0.9222\n",
            "Epoch 850/1000\n",
            "67/67 [==============================] - 0s 6ms/step - loss: 5.9192e-05 - accuracy: 1.0000 - val_loss: 0.9529 - val_accuracy: 0.9222\n",
            "Epoch 851/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.7436e-05 - accuracy: 1.0000 - val_loss: 0.9539 - val_accuracy: 0.9222\n",
            "Epoch 852/1000\n",
            "67/67 [==============================] - 0s 6ms/step - loss: 5.6037e-05 - accuracy: 1.0000 - val_loss: 0.9556 - val_accuracy: 0.9222\n",
            "Epoch 853/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.4270e-05 - accuracy: 1.0000 - val_loss: 0.9565 - val_accuracy: 0.9222\n",
            "Epoch 854/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.2919e-05 - accuracy: 1.0000 - val_loss: 0.9581 - val_accuracy: 0.9222\n",
            "Epoch 855/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.0974e-05 - accuracy: 1.0000 - val_loss: 0.9588 - val_accuracy: 0.9222\n",
            "Epoch 856/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.9708e-05 - accuracy: 1.0000 - val_loss: 0.9605 - val_accuracy: 0.9222\n",
            "Epoch 857/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.8595e-05 - accuracy: 1.0000 - val_loss: 0.9617 - val_accuracy: 0.9222\n",
            "Epoch 858/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.6910e-05 - accuracy: 1.0000 - val_loss: 0.9630 - val_accuracy: 0.9222\n",
            "Epoch 859/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.6111e-05 - accuracy: 1.0000 - val_loss: 0.9637 - val_accuracy: 0.9222\n",
            "Epoch 860/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.5008e-05 - accuracy: 1.0000 - val_loss: 0.9652 - val_accuracy: 0.9222\n",
            "Epoch 861/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.4003e-05 - accuracy: 1.0000 - val_loss: 0.9664 - val_accuracy: 0.9222\n",
            "Epoch 862/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.2648e-05 - accuracy: 1.0000 - val_loss: 0.9672 - val_accuracy: 0.9222\n",
            "Epoch 863/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.1925e-05 - accuracy: 1.0000 - val_loss: 0.9685 - val_accuracy: 0.9222\n",
            "Epoch 864/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.0529e-05 - accuracy: 1.0000 - val_loss: 0.9697 - val_accuracy: 0.9222\n",
            "Epoch 865/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.9632e-05 - accuracy: 1.0000 - val_loss: 0.9709 - val_accuracy: 0.9222\n",
            "Epoch 866/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.8761e-05 - accuracy: 1.0000 - val_loss: 0.9717 - val_accuracy: 0.9222\n",
            "Epoch 867/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.7451e-05 - accuracy: 1.0000 - val_loss: 0.9729 - val_accuracy: 0.9222\n",
            "Epoch 868/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.6353e-05 - accuracy: 1.0000 - val_loss: 0.9741 - val_accuracy: 0.9222\n",
            "Epoch 869/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.5710e-05 - accuracy: 1.0000 - val_loss: 0.9748 - val_accuracy: 0.9222\n",
            "Epoch 870/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.4815e-05 - accuracy: 1.0000 - val_loss: 0.9761 - val_accuracy: 0.9222\n",
            "Epoch 871/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.3782e-05 - accuracy: 1.0000 - val_loss: 0.9775 - val_accuracy: 0.9222\n",
            "Epoch 872/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.3173e-05 - accuracy: 1.0000 - val_loss: 0.9783 - val_accuracy: 0.9222\n",
            "Epoch 873/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.2204e-05 - accuracy: 1.0000 - val_loss: 0.9796 - val_accuracy: 0.9222\n",
            "Epoch 874/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.1493e-05 - accuracy: 1.0000 - val_loss: 0.9807 - val_accuracy: 0.9222\n",
            "Epoch 875/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.0692e-05 - accuracy: 1.0000 - val_loss: 0.9819 - val_accuracy: 0.9222\n",
            "Epoch 876/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.0012e-05 - accuracy: 1.0000 - val_loss: 0.9833 - val_accuracy: 0.9222\n",
            "Epoch 877/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.9806e-05 - accuracy: 1.0000 - val_loss: 0.9846 - val_accuracy: 0.9222\n",
            "Epoch 878/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.8785e-05 - accuracy: 1.0000 - val_loss: 0.9853 - val_accuracy: 0.9222\n",
            "Epoch 879/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.8040e-05 - accuracy: 1.0000 - val_loss: 0.9863 - val_accuracy: 0.9222\n",
            "Epoch 880/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.7562e-05 - accuracy: 1.0000 - val_loss: 0.9871 - val_accuracy: 0.9222\n",
            "Epoch 881/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.6630e-05 - accuracy: 1.0000 - val_loss: 0.9881 - val_accuracy: 0.9222\n",
            "Epoch 882/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.6104e-05 - accuracy: 1.0000 - val_loss: 0.9896 - val_accuracy: 0.9222\n",
            "Epoch 883/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.5398e-05 - accuracy: 1.0000 - val_loss: 0.9911 - val_accuracy: 0.9222\n",
            "Epoch 884/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.4835e-05 - accuracy: 1.0000 - val_loss: 0.9919 - val_accuracy: 0.9222\n",
            "Epoch 885/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.4288e-05 - accuracy: 1.0000 - val_loss: 0.9925 - val_accuracy: 0.9222\n",
            "Epoch 886/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.3631e-05 - accuracy: 1.0000 - val_loss: 0.9936 - val_accuracy: 0.9222\n",
            "Epoch 887/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.3240e-05 - accuracy: 1.0000 - val_loss: 0.9956 - val_accuracy: 0.9222\n",
            "Epoch 888/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.3074e-05 - accuracy: 1.0000 - val_loss: 0.9953 - val_accuracy: 0.9222\n",
            "Epoch 889/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 2.2233e-05 - accuracy: 1.0000 - val_loss: 0.9985 - val_accuracy: 0.9222\n",
            "Epoch 890/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.1773e-05 - accuracy: 1.0000 - val_loss: 0.9981 - val_accuracy: 0.9222\n",
            "Epoch 891/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.1278e-05 - accuracy: 1.0000 - val_loss: 1.0000 - val_accuracy: 0.9222\n",
            "Epoch 892/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.0607e-05 - accuracy: 1.0000 - val_loss: 0.9998 - val_accuracy: 0.9222\n",
            "Epoch 893/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.0127e-05 - accuracy: 1.0000 - val_loss: 1.0021 - val_accuracy: 0.9222\n",
            "Epoch 894/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.9956e-05 - accuracy: 1.0000 - val_loss: 1.0029 - val_accuracy: 0.9222\n",
            "Epoch 895/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.9412e-05 - accuracy: 1.0000 - val_loss: 1.0043 - val_accuracy: 0.9222\n",
            "Epoch 896/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.8813e-05 - accuracy: 1.0000 - val_loss: 1.0050 - val_accuracy: 0.9222\n",
            "Epoch 897/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.8525e-05 - accuracy: 1.0000 - val_loss: 1.0062 - val_accuracy: 0.9222\n",
            "Epoch 898/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.8099e-05 - accuracy: 1.0000 - val_loss: 1.0090 - val_accuracy: 0.9222\n",
            "Epoch 899/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.7569e-05 - accuracy: 1.0000 - val_loss: 1.0097 - val_accuracy: 0.9222\n",
            "Epoch 900/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.7088e-05 - accuracy: 1.0000 - val_loss: 1.0110 - val_accuracy: 0.9222\n",
            "Epoch 901/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.6735e-05 - accuracy: 1.0000 - val_loss: 1.0129 - val_accuracy: 0.9222\n",
            "Epoch 902/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.6541e-05 - accuracy: 1.0000 - val_loss: 1.0140 - val_accuracy: 0.9222\n",
            "Epoch 903/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.6269e-05 - accuracy: 1.0000 - val_loss: 1.0147 - val_accuracy: 0.9222\n",
            "Epoch 904/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.5859e-05 - accuracy: 1.0000 - val_loss: 1.0172 - val_accuracy: 0.9222\n",
            "Epoch 905/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.5480e-05 - accuracy: 1.0000 - val_loss: 1.0182 - val_accuracy: 0.9222\n",
            "Epoch 906/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.5155e-05 - accuracy: 1.0000 - val_loss: 1.0189 - val_accuracy: 0.9222\n",
            "Epoch 907/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.4430e-05 - accuracy: 1.0000 - val_loss: 1.0214 - val_accuracy: 0.9222\n",
            "Epoch 908/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.4504e-05 - accuracy: 1.0000 - val_loss: 1.0216 - val_accuracy: 0.9222\n",
            "Epoch 909/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.3988e-05 - accuracy: 1.0000 - val_loss: 1.0255 - val_accuracy: 0.9222\n",
            "Epoch 910/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.3747e-05 - accuracy: 1.0000 - val_loss: 1.0272 - val_accuracy: 0.9222\n",
            "Epoch 911/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.3622e-05 - accuracy: 1.0000 - val_loss: 1.0270 - val_accuracy: 0.9222\n",
            "Epoch 912/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.3179e-05 - accuracy: 1.0000 - val_loss: 1.0297 - val_accuracy: 0.9222\n",
            "Epoch 913/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.2856e-05 - accuracy: 1.0000 - val_loss: 1.0317 - val_accuracy: 0.9222\n",
            "Epoch 914/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.2464e-05 - accuracy: 1.0000 - val_loss: 1.0314 - val_accuracy: 0.9222\n",
            "Epoch 915/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.2049e-05 - accuracy: 1.0000 - val_loss: 1.0375 - val_accuracy: 0.9222\n",
            "Epoch 916/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.2622e-05 - accuracy: 1.0000 - val_loss: 1.0376 - val_accuracy: 0.9222\n",
            "Epoch 917/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.1739e-05 - accuracy: 1.0000 - val_loss: 1.0388 - val_accuracy: 0.9222\n",
            "Epoch 918/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.1257e-05 - accuracy: 1.0000 - val_loss: 1.0387 - val_accuracy: 0.9222\n",
            "Epoch 919/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.0995e-05 - accuracy: 1.0000 - val_loss: 1.0410 - val_accuracy: 0.9222\n",
            "Epoch 920/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.0883e-05 - accuracy: 1.0000 - val_loss: 1.0430 - val_accuracy: 0.9222\n",
            "Epoch 921/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.0607e-05 - accuracy: 1.0000 - val_loss: 1.0436 - val_accuracy: 0.9222\n",
            "Epoch 922/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.1073e-05 - accuracy: 1.0000 - val_loss: 1.0456 - val_accuracy: 0.9222\n",
            "Epoch 923/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.0343e-05 - accuracy: 1.0000 - val_loss: 1.0514 - val_accuracy: 0.9222\n",
            "Epoch 924/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.1176e-05 - accuracy: 1.0000 - val_loss: 1.0514 - val_accuracy: 0.9222\n",
            "Epoch 925/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.0362e-05 - accuracy: 1.0000 - val_loss: 1.0486 - val_accuracy: 0.9222\n",
            "Epoch 926/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 9.7575e-06 - accuracy: 1.0000 - val_loss: 1.0553 - val_accuracy: 0.9222\n",
            "Epoch 927/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 9.5941e-06 - accuracy: 1.0000 - val_loss: 1.0566 - val_accuracy: 0.9222\n",
            "Epoch 928/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 9.2902e-06 - accuracy: 1.0000 - val_loss: 1.0596 - val_accuracy: 0.9222\n",
            "Epoch 929/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 9.6278e-06 - accuracy: 1.0000 - val_loss: 1.0639 - val_accuracy: 0.9222\n",
            "Epoch 930/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 9.5990e-06 - accuracy: 1.0000 - val_loss: 1.0555 - val_accuracy: 0.9222\n",
            "Epoch 931/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.1589e-05 - accuracy: 1.0000 - val_loss: 1.0618 - val_accuracy: 0.9222\n",
            "Epoch 932/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 8.8935e-06 - accuracy: 1.0000 - val_loss: 1.0682 - val_accuracy: 0.9222\n",
            "Epoch 933/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 9.9597e-06 - accuracy: 1.0000 - val_loss: 1.0720 - val_accuracy: 0.9222\n",
            "Epoch 934/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.1443e-05 - accuracy: 1.0000 - val_loss: 1.0870 - val_accuracy: 0.9184\n",
            "Epoch 935/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 0.9953 - val_loss: 1.2781 - val_accuracy: 0.9165\n",
            "Epoch 936/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.1722 - accuracy: 0.9775 - val_loss: 0.8782 - val_accuracy: 0.9165\n",
            "Epoch 937/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 0.9897 - val_loss: 1.0528 - val_accuracy: 0.9146\n",
            "Epoch 938/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9981 - val_loss: 0.9509 - val_accuracy: 0.9127\n",
            "Epoch 939/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.3775e-04 - accuracy: 1.0000 - val_loss: 0.9363 - val_accuracy: 0.9127\n",
            "Epoch 940/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.8926e-04 - accuracy: 1.0000 - val_loss: 0.9325 - val_accuracy: 0.9146\n",
            "Epoch 941/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.5513e-04 - accuracy: 1.0000 - val_loss: 0.9304 - val_accuracy: 0.9184\n",
            "Epoch 942/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.3918e-04 - accuracy: 1.0000 - val_loss: 0.9291 - val_accuracy: 0.9184\n",
            "Epoch 943/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.2778e-04 - accuracy: 1.0000 - val_loss: 0.9279 - val_accuracy: 0.9184\n",
            "Epoch 944/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.1858e-04 - accuracy: 1.0000 - val_loss: 0.9272 - val_accuracy: 0.9184\n",
            "Epoch 945/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.1146e-04 - accuracy: 1.0000 - val_loss: 0.9273 - val_accuracy: 0.9184\n",
            "Epoch 946/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 1.0578e-04 - accuracy: 1.0000 - val_loss: 0.9272 - val_accuracy: 0.9184\n",
            "Epoch 947/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 1.0092e-04 - accuracy: 1.0000 - val_loss: 0.9273 - val_accuracy: 0.9184\n",
            "Epoch 948/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 9.6932e-05 - accuracy: 1.0000 - val_loss: 0.9277 - val_accuracy: 0.9184\n",
            "Epoch 949/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 9.3360e-05 - accuracy: 1.0000 - val_loss: 0.9279 - val_accuracy: 0.9203\n",
            "Epoch 950/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 8.9793e-05 - accuracy: 1.0000 - val_loss: 0.9284 - val_accuracy: 0.9203\n",
            "Epoch 951/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 8.6731e-05 - accuracy: 1.0000 - val_loss: 0.9287 - val_accuracy: 0.9203\n",
            "Epoch 952/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 8.4125e-05 - accuracy: 1.0000 - val_loss: 0.9291 - val_accuracy: 0.9203\n",
            "Epoch 953/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 8.1840e-05 - accuracy: 1.0000 - val_loss: 0.9300 - val_accuracy: 0.9203\n",
            "Epoch 954/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 7.9511e-05 - accuracy: 1.0000 - val_loss: 0.9310 - val_accuracy: 0.9203\n",
            "Epoch 955/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 7.7217e-05 - accuracy: 1.0000 - val_loss: 0.9322 - val_accuracy: 0.9203\n",
            "Epoch 956/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 7.5652e-05 - accuracy: 1.0000 - val_loss: 0.9330 - val_accuracy: 0.9203\n",
            "Epoch 957/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 7.3466e-05 - accuracy: 1.0000 - val_loss: 0.9328 - val_accuracy: 0.9203\n",
            "Epoch 958/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 7.1002e-05 - accuracy: 1.0000 - val_loss: 0.9348 - val_accuracy: 0.9203\n",
            "Epoch 959/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 6.9383e-05 - accuracy: 1.0000 - val_loss: 0.9353 - val_accuracy: 0.9184\n",
            "Epoch 960/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 6.7822e-05 - accuracy: 1.0000 - val_loss: 0.9369 - val_accuracy: 0.9184\n",
            "Epoch 961/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 6.5869e-05 - accuracy: 1.0000 - val_loss: 0.9377 - val_accuracy: 0.9184\n",
            "Epoch 962/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 6.4734e-05 - accuracy: 1.0000 - val_loss: 0.9385 - val_accuracy: 0.9184\n",
            "Epoch 963/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 6.3039e-05 - accuracy: 1.0000 - val_loss: 0.9403 - val_accuracy: 0.9184\n",
            "Epoch 964/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 6.1582e-05 - accuracy: 1.0000 - val_loss: 0.9409 - val_accuracy: 0.9184\n",
            "Epoch 965/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 6.0258e-05 - accuracy: 1.0000 - val_loss: 0.9418 - val_accuracy: 0.9184\n",
            "Epoch 966/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.8778e-05 - accuracy: 1.0000 - val_loss: 0.9429 - val_accuracy: 0.9184\n",
            "Epoch 967/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.7336e-05 - accuracy: 1.0000 - val_loss: 0.9436 - val_accuracy: 0.9184\n",
            "Epoch 968/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.6015e-05 - accuracy: 1.0000 - val_loss: 0.9447 - val_accuracy: 0.9184\n",
            "Epoch 969/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.4990e-05 - accuracy: 1.0000 - val_loss: 0.9454 - val_accuracy: 0.9165\n",
            "Epoch 970/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.3455e-05 - accuracy: 1.0000 - val_loss: 0.9475 - val_accuracy: 0.9165\n",
            "Epoch 971/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.2698e-05 - accuracy: 1.0000 - val_loss: 0.9480 - val_accuracy: 0.9146\n",
            "Epoch 972/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.1568e-05 - accuracy: 1.0000 - val_loss: 0.9495 - val_accuracy: 0.9146\n",
            "Epoch 973/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 5.0357e-05 - accuracy: 1.0000 - val_loss: 0.9505 - val_accuracy: 0.9146\n",
            "Epoch 974/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.8678e-05 - accuracy: 1.0000 - val_loss: 0.9516 - val_accuracy: 0.9146\n",
            "Epoch 975/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.7890e-05 - accuracy: 1.0000 - val_loss: 0.9524 - val_accuracy: 0.9146\n",
            "Epoch 976/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.7032e-05 - accuracy: 1.0000 - val_loss: 0.9537 - val_accuracy: 0.9146\n",
            "Epoch 977/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.6109e-05 - accuracy: 1.0000 - val_loss: 0.9550 - val_accuracy: 0.9146\n",
            "Epoch 978/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.4543e-05 - accuracy: 1.0000 - val_loss: 0.9566 - val_accuracy: 0.9146\n",
            "Epoch 979/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.4085e-05 - accuracy: 1.0000 - val_loss: 0.9579 - val_accuracy: 0.9146\n",
            "Epoch 980/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.3389e-05 - accuracy: 1.0000 - val_loss: 0.9581 - val_accuracy: 0.9146\n",
            "Epoch 981/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.2055e-05 - accuracy: 1.0000 - val_loss: 0.9602 - val_accuracy: 0.9146\n",
            "Epoch 982/1000\n",
            "67/67 [==============================] - 0s 3ms/step - loss: 4.1080e-05 - accuracy: 1.0000 - val_loss: 0.9611 - val_accuracy: 0.9146\n",
            "Epoch 983/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 4.0122e-05 - accuracy: 1.0000 - val_loss: 0.9619 - val_accuracy: 0.9146\n",
            "Epoch 984/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.9355e-05 - accuracy: 1.0000 - val_loss: 0.9635 - val_accuracy: 0.9146\n",
            "Epoch 985/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.8072e-05 - accuracy: 1.0000 - val_loss: 0.9645 - val_accuracy: 0.9146\n",
            "Epoch 986/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.7550e-05 - accuracy: 1.0000 - val_loss: 0.9655 - val_accuracy: 0.9146\n",
            "Epoch 987/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.6826e-05 - accuracy: 1.0000 - val_loss: 0.9672 - val_accuracy: 0.9146\n",
            "Epoch 988/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.5717e-05 - accuracy: 1.0000 - val_loss: 0.9682 - val_accuracy: 0.9146\n",
            "Epoch 989/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.5069e-05 - accuracy: 1.0000 - val_loss: 0.9698 - val_accuracy: 0.9146\n",
            "Epoch 990/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.4244e-05 - accuracy: 1.0000 - val_loss: 0.9707 - val_accuracy: 0.9146\n",
            "Epoch 991/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.3450e-05 - accuracy: 1.0000 - val_loss: 0.9721 - val_accuracy: 0.9146\n",
            "Epoch 992/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.2914e-05 - accuracy: 1.0000 - val_loss: 0.9736 - val_accuracy: 0.9146\n",
            "Epoch 993/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.2404e-05 - accuracy: 1.0000 - val_loss: 0.9745 - val_accuracy: 0.9146\n",
            "Epoch 994/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.1314e-05 - accuracy: 1.0000 - val_loss: 0.9761 - val_accuracy: 0.9146\n",
            "Epoch 995/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.0925e-05 - accuracy: 1.0000 - val_loss: 0.9768 - val_accuracy: 0.9146\n",
            "Epoch 996/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 3.0278e-05 - accuracy: 1.0000 - val_loss: 0.9787 - val_accuracy: 0.9146\n",
            "Epoch 997/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.9354e-05 - accuracy: 1.0000 - val_loss: 0.9796 - val_accuracy: 0.9146\n",
            "Epoch 998/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.8835e-05 - accuracy: 1.0000 - val_loss: 0.9798 - val_accuracy: 0.9146\n",
            "Epoch 999/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.8077e-05 - accuracy: 1.0000 - val_loss: 0.9837 - val_accuracy: 0.9146\n",
            "Epoch 1000/1000\n",
            "67/67 [==============================] - 0s 4ms/step - loss: 2.7770e-05 - accuracy: 1.0000 - val_loss: 0.9843 - val_accuracy: 0.9146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_history.history.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MfS0epvwzi4",
        "outputId": "691c6def-eddc-46d9-9253-3c734bfbcc6e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(model_history.history['accuracy'])\n",
        "plt.plot(model_history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "r7xjcTx-1_U1",
        "outputId": "f920a229-45e4-478e-e746-d25230c355a9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(model_history.history['loss'])\n",
        "plt.plot(model_history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "jeEc71wa1_Zn",
        "outputId": "1e19c11f-f0cc-46d0-d532-eb09f231b634"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)"
      ],
      "metadata": {
        "id": "DJaJKi3-2Kha"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "QYgWNrnp2KtE"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVmLLeBM4mFW",
        "outputId": "387406c6-4d4d-40cb-b7e5-0092cdd794cf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[388,  22],\n",
              "       [ 21, 101]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "score=accuracy_score(y_pred,y_test)"
      ],
      "metadata": {
        "id": "wGOaAZGM2Kzh"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMWcf55_2K5i",
        "outputId": "db6bb547-8bbf-49c0-c2a7-181c18580862"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9191729323308271"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}